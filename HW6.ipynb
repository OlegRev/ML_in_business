{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание\n",
    "\n",
    "1. взять любой набор данных для бинарной классификации (можно скачать один из модельных с https://archive.ics.uci.edu/ml/datasets.php)\n",
    "3. сделать feature engineering\n",
    "4. обучить любой классификатор (какой вам нравится)\n",
    "5. далее разделить ваш набор данных на два множества: P (positives) и U (unlabeled). Причем брать нужно не все положительные (класс 1) примеры, а только лишь часть\n",
    "6. применить random negative sampling для построения классификатора в новых условиях\n",
    "7. сравнить качество с решением из пункта 4 (построить отчет - таблицу метрик)\n",
    "8. поэкспериментировать с долей P на шаге 5 (как будет меняться качество модели при уменьшении/увеличении размера P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расмотрим пример на датасете из репозитория UCI\n",
    "\n",
    "Описание данных - https://archive.ics.uci.edu/ml/datasets/ionosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd; pd.set_option('display.max_columns', None)\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import  precision_score, roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score, accuracy_score, classification_report, precision_recall_curve\n",
    "\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]\n",
    "    \n",
    "class OHEEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.columns = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = [col for col in pd.get_dummies(X, prefix=self.key).columns]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.get_dummies(X, prefix=self.key)\n",
    "        test_columns = [col for col in X.columns]\n",
    "        for col_ in test_columns:\n",
    "            if col_ not in self.columns:\n",
    "                X[col_] = 0\n",
    "        return X[self.columns]\n",
    "\n",
    "\n",
    "class RenameKey(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, new_old_keys_dict):\n",
    "        self.new_old_keys_dict = new_old_keys_dict\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.rename(self.new_old_keys_dict, axis='columns')\n",
    "        return X\n",
    "    \n",
    "    \n",
    "class BinEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key, neg_class=None):\n",
    "        self.key = key\n",
    "        self.neg_class = neg_class\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.neg_class in X[self.key].unique():\n",
    "            X.loc[(X[self.key] != self.neg_class), self.key ] = 1\n",
    "            X.loc[(X[self.key] == self.neg_class), self.key ] = 0\n",
    "            X[self.key] = pd.to_numeric(X[self.key])\n",
    "            return X[[self.key]]\n",
    "\n",
    "class RandomNegativeSamplingPU(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, new_key_name='class_test', share_of_positive_classes=0.35):\n",
    "        self.new_key_name = new_key_name\n",
    "        self.share_of_positive_classes = share_of_positive_classes\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        mod_data = X.copy()\n",
    "        pos_ind = np.where(mod_data.iloc[:,-1].values == 1)[0]\n",
    "        np.random.shuffle(pos_ind)\n",
    "        pos_sample_len = int(np.ceil(self.share_of_positive_classes * len(pos_ind)))\n",
    "        pos_sample = pos_ind[:pos_sample_len]\n",
    "        \n",
    "        mod_data[self.new_key_name] = -1\n",
    "        mod_data.loc[pos_sample,self.new_key_name] = 1\n",
    "        \n",
    "        # перемешивает датасет\n",
    "        mod_data = mod_data.sample(frac=1)\n",
    "        # к отрицательному классу относим срез по немаркированому датасету\n",
    "        # в количестве равном количеству положительных сигналов(строк)\n",
    "        neg_sample = mod_data[mod_data[self.new_key_name]==-1][:pos_sample_len]\n",
    "        # выделяем остальной немаркированный датасет для теста \n",
    "        sample_test = mod_data[mod_data[self.new_key_name]==-1][pos_sample_len:]\n",
    "        # положительный датасет\n",
    "        pos_sample = mod_data[mod_data[self.new_key_name]==1]\n",
    "        # соединяем положительный и отрицательный датасеты с перемешиванием\n",
    "        sample_train = pd.concat([neg_sample, pos_sample]).sample(frac=1)\n",
    "        \n",
    "        # X_sample_train = sample_train.iloc[:,:-2]\n",
    "        # y_sample_train= sample_train.iloc[:,-2]\n",
    "        # X_sample_test = sample_test.iloc[:,:-2]\n",
    "        # y_sample_test = sample_test.iloc[:,-2]\n",
    "        return sample_train, sample_test # X_sample_train, y_sample_train, X_sample_test, y_sample_test\n",
    "        \n",
    "        \n",
    "\n",
    "def evaluate_results(y_test, y_predict, fstr=True):\n",
    "    f1 = f1_score(y_test, y_predict)\n",
    "    roc = roc_auc_score(y_test, y_predict)\n",
    "    prc = precision_score(y_test, y_predict, average='binary')\n",
    "    rec = recall_score(y_test, y_predict, average='binary')\n",
    "    if fstr:\n",
    "        return (f'Classification results:\\n'\n",
    "                f'F1_Score: \\t{(f1*100.0):.3f}%\\n'\n",
    "                f'Roc_AUC: \\t{(roc*100.0):.3f}%\\n'\n",
    "                f'Precision: \\t{(prc*100.0):.3f}%\\n'\n",
    "                f'Recall: \\t{(rec*100.0):.3f}%')\n",
    "    else:\n",
    "        return None, f1, roc, prc, rec\n",
    "        \n",
    "\n",
    "    \n",
    "def get_metrics(y_test, probs, fstr=True):\n",
    "    \"\"\"\n",
    "    Функция перехода от вероятностей к меткам классов.\n",
    "    Для этого нужно подобрать порог - Best_Threshold={thresholds[ix]:.3f},\n",
    "    после которого мы считаем,\n",
    "    что объект можно отнести к классу 1 \n",
    "    (если вероятность больше порога -\n",
    "    размечаем объект как класс 1,\n",
    "    если нет - класс 0)\n",
    "\n",
    "    Args:\n",
    "        y_test ([type]): [Истинные классы]\n",
    "        probs ([type]): [Предсказанные вероятности принадлежности к классу]\n",
    "        fstr (bool, optional): [флаг вывода]. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        if fstr is True:\n",
    "            [f'str']: [Выводиться f-string в виде: \n",
    "                        f'Best_Threshold={thresholds[ix]:.3f},\\n'\n",
    "                        f'F_Score={fscore[ix]:.3f},\\n'\n",
    "                        f'Precision={precision[ix]:.3f},\\n'\n",
    "                        f'Recall={recall[ix]:.3f},\\n'\n",
    "                        f'Roc_AUC={roc_auc_score(y_test, probs)}']\n",
    "        else:\n",
    "            [tuple]: [(\n",
    "                       thresholds[ix]: float,\n",
    "                       fscore[ix]: float,\n",
    "                       precision[ix]: float,\n",
    "                       recall[ix]: float,\n",
    "                       roc_auc_score(y_test, probs): float\n",
    "                       )]\n",
    "    \"\"\"\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, probs)\n",
    "\n",
    "    fscore = (2 * precision * recall) / (precision + recall)\n",
    "    roc = roc_auc_score(y_test, probs)\n",
    "    ix = np.argmax(fscore)\n",
    "    if fstr:\n",
    "        return(f'Best_Threshold:\\t{thresholds[ix]:.3f},\\n'\n",
    "               f'F1_Score:\\t{(fscore[ix]*100.0):.3f}%,\\n'\n",
    "               f'Roc_AUC:\\t{(roc*100.0):.3f}%,\\n'\n",
    "               f'Precision:\\t{(precision[ix]*100.0):.3f}%,\\n'\n",
    "               f'Recall: \\t{(recall[ix]*100.0):.3f}%')\n",
    "    else:\n",
    "        return thresholds[ix], fscore[ix], roc, precision[ix], recall[ix]\n",
    "    \n",
    "def get_plot_bar(score, score_probs, df_score, score_name, kind='bar'):\n",
    "    f_score_bar = pd.DataFrame({'Score':score,\n",
    "                                'Score_probs':score_probs},\n",
    "                               index=df_score.columns)\n",
    "    ax = f_score_bar.plot(kind=kind, title=score_name)\n",
    "    ax.legend([\"Score\", \"Score_probs\"])\n",
    "    h,l = ax.get_legend_handles_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Title: Johns Hopkins University Ionosphere database\n",
      "\n",
      "2. Source Information:\n",
      "   -- Donor: Vince Sigillito (vgs@aplcen.apl.jhu.edu)\n",
      "   -- Date: 1989\n",
      "   -- Source: Space Physics Group\n",
      "              Applied Physics Laboratory\n",
      "              Johns Hopkins University\n",
      "              Johns Hopkins Road\n",
      "              Laurel, MD 20723 \n",
      "\n",
      "3. Past Usage:\n",
      "   -- Sigillito, V. G., Wing, S. P., Hutton, L. V., \\& Baker, K. B. (1989).\n",
      "      Classification of radar returns from the ionosphere using neural \n",
      "      networks. Johns Hopkins APL Technical Digest, 10, 262-266.\n",
      "\n",
      "      They investigated using backprop and the perceptron training algorithm\n",
      "      on this database.  Using the first 200 instances for training, which\n",
      "      were carefully split almost 50% positive and 50% negative, they found\n",
      "      that a \"linear\" perceptron attained 90.7%, a \"non-linear\" perceptron\n",
      "      attained 92%, and backprop an average of over 96% accuracy on the \n",
      "      remaining 150 test instances, consisting of 123 \"good\" and only 24 \"bad\"\n",
      "      instances.  (There was a counting error or some mistake somewhere; there\n",
      "      are a total of 351 rather than 350 instances in this domain.) Accuracy\n",
      "      on \"good\" instances was much higher than for \"bad\" instances.  Backprop\n",
      "      was tested with several different numbers of hidden units (in [0,15])\n",
      "      and incremental results were also reported (corresponding to how well\n",
      "      the different variants of backprop did after a periodic number of \n",
      "      epochs).\n",
      "\n",
      "      David Aha (aha@ics.uci.edu) briefly investigated this database.\n",
      "      He found that nearest neighbor attains an accuracy of 92.1%, that\n",
      "      Ross Quinlan's C4 algorithm attains 94.0% (no windowing), and that\n",
      "      IB3 (Aha \\& Kibler, IJCAI-1989) attained 96.7% (parameter settings:\n",
      "      70% and 80% for acceptance and dropping respectively).\n",
      "\n",
      "4. Relevant Information:\n",
      "   This radar data was collected by a system in Goose Bay, Labrador.  This\n",
      "   system consists of a phased array of 16 high-frequency antennas with a\n",
      "   total transmitted power on the order of 6.4 kilowatts.  See the paper\n",
      "   for more details.  The targets were free electrons in the ionosphere.\n",
      "   \"Good\" radar returns are those showing evidence of some type of structure \n",
      "   in the ionosphere.  \"Bad\" returns are those that do not; their signals pass\n",
      "   through the ionosphere.  \n",
      "\n",
      "   Received signals were processed using an autocorrelation function whose\n",
      "   arguments are the time of a pulse and the pulse number.  There were 17\n",
      "   pulse numbers for the Goose Bay system.  Instances in this databse are\n",
      "   described by 2 attributes per pulse number, corresponding to the complex\n",
      "   values returned by the function resulting from the complex electromagnetic\n",
      "   signal.\n",
      "\n",
      "5. Number of Instances: 351\n",
      "\n",
      "6. Number of Attributes: 34 plus the class attribute\n",
      "   -- All 34 predictor attributes are continuous\n",
      "\n",
      "7. Attribute Information:     \n",
      "   -- All 34 are continuous, as described above\n",
      "   -- The 35th attribute is either \"good\" or \"bad\" according to the definition\n",
      "      summarized above.  This is a binary classification task.\n",
      "\n",
      "8. Missing Values: None\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"ionosphere_description.txt\") as file:\n",
    "    data_description = file.read()\n",
    "print(data_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>-0.17755</td>\n",
       "      <td>0.59755</td>\n",
       "      <td>-0.44945</td>\n",
       "      <td>0.60536</td>\n",
       "      <td>-0.38223</td>\n",
       "      <td>0.84356</td>\n",
       "      <td>-0.38542</td>\n",
       "      <td>0.58212</td>\n",
       "      <td>-0.32192</td>\n",
       "      <td>0.56971</td>\n",
       "      <td>-0.29674</td>\n",
       "      <td>0.36946</td>\n",
       "      <td>-0.47357</td>\n",
       "      <td>0.56811</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>0.50874</td>\n",
       "      <td>-0.67743</td>\n",
       "      <td>0.34432</td>\n",
       "      <td>-0.69707</td>\n",
       "      <td>-0.51685</td>\n",
       "      <td>-0.97515</td>\n",
       "      <td>0.05499</td>\n",
       "      <td>-0.62237</td>\n",
       "      <td>0.33109</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-0.13151</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>-0.18056</td>\n",
       "      <td>-0.35734</td>\n",
       "      <td>-0.20332</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>0.73082</td>\n",
       "      <td>0.05346</td>\n",
       "      <td>0.85443</td>\n",
       "      <td>0.00827</td>\n",
       "      <td>0.54591</td>\n",
       "      <td>0.00299</td>\n",
       "      <td>0.83775</td>\n",
       "      <td>-0.13644</td>\n",
       "      <td>0.75535</td>\n",
       "      <td>-0.08540</td>\n",
       "      <td>0.70887</td>\n",
       "      <td>-0.27502</td>\n",
       "      <td>0.43385</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.57528</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1        2        3        4        5        6        7        8   \\\n",
       "0   1   0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000   \n",
       "1   1   0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000   \n",
       "2   1   0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965   \n",
       "\n",
       "        9        10       11       12       13       14       15       16  \\\n",
       "0  0.03760  0.85243 -0.17755  0.59755 -0.44945  0.60536 -0.38223  0.84356   \n",
       "1 -0.04549  0.50874 -0.67743  0.34432 -0.69707 -0.51685 -0.97515  0.05499   \n",
       "2  0.01198  0.73082  0.05346  0.85443  0.00827  0.54591  0.00299  0.83775   \n",
       "\n",
       "        17       18       19       20       21       22       23       24  \\\n",
       "0 -0.38542  0.58212 -0.32192  0.56971 -0.29674  0.36946 -0.47357  0.56811   \n",
       "1 -0.62237  0.33109 -1.00000 -0.13151 -0.45300 -0.18056 -0.35734 -0.20332   \n",
       "2 -0.13644  0.75535 -0.08540  0.70887 -0.27502  0.43385 -0.12062  0.57528   \n",
       "\n",
       "        25       26       27       28       29       30       31       32  \\\n",
       "0 -0.51171  0.41078 -0.46168  0.21266 -0.34090  0.42267 -0.54487  0.18641   \n",
       "1 -0.26569 -0.20468 -0.18401 -0.19040 -0.11593 -0.16626 -0.06288 -0.13738   \n",
       "2 -0.40220  0.58984 -0.22145  0.43100 -0.17365  0.60436 -0.24180  0.56045   \n",
       "\n",
       "        33 34  \n",
       "0 -0.45300  g  \n",
       "1 -0.02447  b  \n",
       "2 -0.38238  g  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"ionosphere_data.txt\", header=None)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 351 entries, 0 to 350\n",
      "Data columns (total 35 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       351 non-null    int64  \n",
      " 1   1       351 non-null    int64  \n",
      " 2   2       351 non-null    float64\n",
      " 3   3       351 non-null    float64\n",
      " 4   4       351 non-null    float64\n",
      " 5   5       351 non-null    float64\n",
      " 6   6       351 non-null    float64\n",
      " 7   7       351 non-null    float64\n",
      " 8   8       351 non-null    float64\n",
      " 9   9       351 non-null    float64\n",
      " 10  10      351 non-null    float64\n",
      " 11  11      351 non-null    float64\n",
      " 12  12      351 non-null    float64\n",
      " 13  13      351 non-null    float64\n",
      " 14  14      351 non-null    float64\n",
      " 15  15      351 non-null    float64\n",
      " 16  16      351 non-null    float64\n",
      " 17  17      351 non-null    float64\n",
      " 18  18      351 non-null    float64\n",
      " 19  19      351 non-null    float64\n",
      " 20  20      351 non-null    float64\n",
      " 21  21      351 non-null    float64\n",
      " 22  22      351 non-null    float64\n",
      " 23  23      351 non-null    float64\n",
      " 24  24      351 non-null    float64\n",
      " 25  25      351 non-null    float64\n",
      " 26  26      351 non-null    float64\n",
      " 27  27      351 non-null    float64\n",
      " 28  28      351 non-null    float64\n",
      " 29  29      351 non-null    float64\n",
      " 30  30      351 non-null    float64\n",
      " 31  31      351 non-null    float64\n",
      " 32  32      351 non-null    float64\n",
      " 33  33      351 non-null    float64\n",
      " 34  34      351 non-null    object \n",
      "dtypes: float64(32), int64(2), object(1)\n",
      "memory usage: 96.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.0</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.891738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.641342</td>\n",
       "      <td>0.044372</td>\n",
       "      <td>0.601068</td>\n",
       "      <td>0.115889</td>\n",
       "      <td>0.550095</td>\n",
       "      <td>0.119360</td>\n",
       "      <td>0.511848</td>\n",
       "      <td>0.181345</td>\n",
       "      <td>0.476183</td>\n",
       "      <td>0.155040</td>\n",
       "      <td>0.400801</td>\n",
       "      <td>0.093414</td>\n",
       "      <td>0.344159</td>\n",
       "      <td>0.071132</td>\n",
       "      <td>0.381949</td>\n",
       "      <td>-0.003617</td>\n",
       "      <td>0.359390</td>\n",
       "      <td>-0.024025</td>\n",
       "      <td>0.336695</td>\n",
       "      <td>0.008296</td>\n",
       "      <td>0.362475</td>\n",
       "      <td>-0.057406</td>\n",
       "      <td>0.396135</td>\n",
       "      <td>-0.071187</td>\n",
       "      <td>0.541641</td>\n",
       "      <td>-0.069538</td>\n",
       "      <td>0.378445</td>\n",
       "      <td>-0.027907</td>\n",
       "      <td>0.352514</td>\n",
       "      <td>-0.003794</td>\n",
       "      <td>0.349364</td>\n",
       "      <td>0.014480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.311155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.497708</td>\n",
       "      <td>0.441435</td>\n",
       "      <td>0.519862</td>\n",
       "      <td>0.460810</td>\n",
       "      <td>0.492654</td>\n",
       "      <td>0.520750</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>0.483851</td>\n",
       "      <td>0.563496</td>\n",
       "      <td>0.494817</td>\n",
       "      <td>0.622186</td>\n",
       "      <td>0.494873</td>\n",
       "      <td>0.652828</td>\n",
       "      <td>0.458371</td>\n",
       "      <td>0.618020</td>\n",
       "      <td>0.496762</td>\n",
       "      <td>0.626267</td>\n",
       "      <td>0.519076</td>\n",
       "      <td>0.609828</td>\n",
       "      <td>0.518166</td>\n",
       "      <td>0.603767</td>\n",
       "      <td>0.527456</td>\n",
       "      <td>0.578451</td>\n",
       "      <td>0.508495</td>\n",
       "      <td>0.516205</td>\n",
       "      <td>0.550025</td>\n",
       "      <td>0.575886</td>\n",
       "      <td>0.507974</td>\n",
       "      <td>0.571483</td>\n",
       "      <td>0.513574</td>\n",
       "      <td>0.522663</td>\n",
       "      <td>0.468337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472135</td>\n",
       "      <td>-0.064735</td>\n",
       "      <td>0.412660</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>0.211310</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.087110</td>\n",
       "      <td>-0.048075</td>\n",
       "      <td>0.021120</td>\n",
       "      <td>-0.065265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.073725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.081705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.225690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.234670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.243870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.366885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.332390</td>\n",
       "      <td>0.286435</td>\n",
       "      <td>-0.443165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.236885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.242595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.165350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.871110</td>\n",
       "      <td>0.016310</td>\n",
       "      <td>0.809200</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.728730</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.684210</td>\n",
       "      <td>0.018290</td>\n",
       "      <td>0.667980</td>\n",
       "      <td>0.028250</td>\n",
       "      <td>0.644070</td>\n",
       "      <td>0.030270</td>\n",
       "      <td>0.601940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.590910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.576190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.499090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.531760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.553890</td>\n",
       "      <td>-0.015050</td>\n",
       "      <td>0.708240</td>\n",
       "      <td>-0.017690</td>\n",
       "      <td>0.496640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.442770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409560</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.194185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.334655</td>\n",
       "      <td>0.969240</td>\n",
       "      <td>0.445675</td>\n",
       "      <td>0.953240</td>\n",
       "      <td>0.534195</td>\n",
       "      <td>0.957895</td>\n",
       "      <td>0.482375</td>\n",
       "      <td>0.955505</td>\n",
       "      <td>0.374860</td>\n",
       "      <td>0.919330</td>\n",
       "      <td>0.308975</td>\n",
       "      <td>0.935705</td>\n",
       "      <td>0.195285</td>\n",
       "      <td>0.899265</td>\n",
       "      <td>0.134370</td>\n",
       "      <td>0.894865</td>\n",
       "      <td>0.188760</td>\n",
       "      <td>0.911235</td>\n",
       "      <td>0.164630</td>\n",
       "      <td>0.905240</td>\n",
       "      <td>0.156765</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.153535</td>\n",
       "      <td>0.883465</td>\n",
       "      <td>0.154075</td>\n",
       "      <td>0.857620</td>\n",
       "      <td>0.200120</td>\n",
       "      <td>0.813765</td>\n",
       "      <td>0.171660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0      1           2           3           4           5   \\\n",
       "count  351.000000  351.0  351.000000  351.000000  351.000000  351.000000   \n",
       "mean     0.891738    0.0    0.641342    0.044372    0.601068    0.115889   \n",
       "std      0.311155    0.0    0.497708    0.441435    0.519862    0.460810   \n",
       "min      0.000000    0.0   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%      1.000000    0.0    0.472135   -0.064735    0.412660   -0.024795   \n",
       "50%      1.000000    0.0    0.871110    0.016310    0.809200    0.022800   \n",
       "75%      1.000000    0.0    1.000000    0.194185    1.000000    0.334655   \n",
       "max      1.000000    0.0    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  351.000000  351.000000   \n",
       "mean     0.550095    0.119360    0.511848    0.181345    0.476183    0.155040   \n",
       "std      0.492654    0.520750    0.507066    0.483851    0.563496    0.494817   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%      0.211310   -0.054840    0.087110   -0.048075    0.021120   -0.065265   \n",
       "50%      0.728730    0.014710    0.684210    0.018290    0.667980    0.028250   \n",
       "75%      0.969240    0.445675    0.953240    0.534195    0.957895    0.482375   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               12          13          14          15          16          17  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  351.000000  351.000000   \n",
       "mean     0.400801    0.093414    0.344159    0.071132    0.381949   -0.003617   \n",
       "std      0.622186    0.494873    0.652828    0.458371    0.618020    0.496762   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%      0.000000   -0.073725    0.000000   -0.081705    0.000000   -0.225690   \n",
       "50%      0.644070    0.030270    0.601940    0.000000    0.590910    0.000000   \n",
       "75%      0.955505    0.374860    0.919330    0.308975    0.935705    0.195285   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               18          19          20          21          22          23  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  351.000000  351.000000   \n",
       "mean     0.359390   -0.024025    0.336695    0.008296    0.362475   -0.057406   \n",
       "std      0.626267    0.519076    0.609828    0.518166    0.603767    0.527456   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%      0.000000   -0.234670    0.000000   -0.243870    0.000000   -0.366885   \n",
       "50%      0.576190    0.000000    0.499090    0.000000    0.531760    0.000000   \n",
       "75%      0.899265    0.134370    0.894865    0.188760    0.911235    0.164630   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               24          25          26          27          28          29  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  351.000000  351.000000   \n",
       "mean     0.396135   -0.071187    0.541641   -0.069538    0.378445   -0.027907   \n",
       "std      0.578451    0.508495    0.516205    0.550025    0.575886    0.507974   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%      0.000000   -0.332390    0.286435   -0.443165    0.000000   -0.236885   \n",
       "50%      0.553890   -0.015050    0.708240   -0.017690    0.496640    0.000000   \n",
       "75%      0.905240    0.156765    0.999945    0.153535    0.883465    0.154075   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               30          31          32          33  \n",
       "count  351.000000  351.000000  351.000000  351.000000  \n",
       "mean     0.352514   -0.003794    0.349364    0.014480  \n",
       "std      0.571483    0.513574    0.522663    0.468337  \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000  \n",
       "25%      0.000000   -0.242595    0.000000   -0.165350  \n",
       "50%      0.442770    0.000000    0.409560    0.000000  \n",
       "75%      0.857620    0.200120    0.813765    0.171660  \n",
       "max      1.000000    1.000000    1.000000    1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Наш таргет\n",
    "    \"good\" or \"bad\"\n",
    "    g - good\n",
    "    b - bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['g', 'b'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[34].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>-0.17755</td>\n",
       "      <td>0.59755</td>\n",
       "      <td>-0.44945</td>\n",
       "      <td>0.60536</td>\n",
       "      <td>-0.38223</td>\n",
       "      <td>0.84356</td>\n",
       "      <td>-0.38542</td>\n",
       "      <td>0.58212</td>\n",
       "      <td>-0.32192</td>\n",
       "      <td>0.56971</td>\n",
       "      <td>-0.29674</td>\n",
       "      <td>0.36946</td>\n",
       "      <td>-0.47357</td>\n",
       "      <td>0.56811</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>0.50874</td>\n",
       "      <td>-0.67743</td>\n",
       "      <td>0.34432</td>\n",
       "      <td>-0.69707</td>\n",
       "      <td>-0.51685</td>\n",
       "      <td>-0.97515</td>\n",
       "      <td>0.05499</td>\n",
       "      <td>-0.62237</td>\n",
       "      <td>0.33109</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-0.13151</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>-0.18056</td>\n",
       "      <td>-0.35734</td>\n",
       "      <td>-0.20332</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>0.73082</td>\n",
       "      <td>0.05346</td>\n",
       "      <td>0.85443</td>\n",
       "      <td>0.00827</td>\n",
       "      <td>0.54591</td>\n",
       "      <td>0.00299</td>\n",
       "      <td>0.83775</td>\n",
       "      <td>-0.13644</td>\n",
       "      <td>0.75535</td>\n",
       "      <td>-0.08540</td>\n",
       "      <td>0.70887</td>\n",
       "      <td>-0.27502</td>\n",
       "      <td>0.43385</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.57528</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1        2        3        4        5        6        7        8   \\\n",
       "0   1   0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000   \n",
       "1   1   0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000   \n",
       "2   1   0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965   \n",
       "\n",
       "        9        10       11       12       13       14       15       16  \\\n",
       "0  0.03760  0.85243 -0.17755  0.59755 -0.44945  0.60536 -0.38223  0.84356   \n",
       "1 -0.04549  0.50874 -0.67743  0.34432 -0.69707 -0.51685 -0.97515  0.05499   \n",
       "2  0.01198  0.73082  0.05346  0.85443  0.00827  0.54591  0.00299  0.83775   \n",
       "\n",
       "        17       18       19       20       21       22       23       24  \\\n",
       "0 -0.38542  0.58212 -0.32192  0.56971 -0.29674  0.36946 -0.47357  0.56811   \n",
       "1 -0.62237  0.33109 -1.00000 -0.13151 -0.45300 -0.18056 -0.35734 -0.20332   \n",
       "2 -0.13644  0.75535 -0.08540  0.70887 -0.27502  0.43385 -0.12062  0.57528   \n",
       "\n",
       "        25       26       27       28       29       30       31       32  \\\n",
       "0 -0.51171  0.41078 -0.46168  0.21266 -0.34090  0.42267 -0.54487  0.18641   \n",
       "1 -0.26569 -0.20468 -0.18401 -0.19040 -0.11593 -0.16626 -0.06288 -0.13738   \n",
       "2 -0.40220  0.58984 -0.22145  0.43100 -0.17365  0.60436 -0.24180  0.56045   \n",
       "\n",
       "        33 34  \n",
       "0 -0.45300  g  \n",
       "1 -0.02447  b  \n",
       "2 -0.38238  g  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base = data.copy()\n",
    "df_base.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_feture = RenameKey({34: 'target'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = rename_feture.fit_transform(df_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target\n",
       "0       1\n",
       "1       0\n",
       "2       1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_bin = BinEncoder(key='target', neg_class='b')\n",
    "target_bin.fit_transform(df_base).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас есть 34 признака и 1 целевая переменная (бинарная) - нужно определить хороший сигнал или нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(351, 35)\n"
     ]
    }
   ],
   "source": [
    "print(df_base.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всего 351 сигнал"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на соотношение классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    225\n",
       "0    126\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base.iloc[:, -1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuos_features = Pipeline([\n",
    "                ('selector', ColumnSelector(key=[_ for _ in range(34)]))\n",
    "            ])\n",
    "\n",
    "feats = FeatureUnion([('continuos_features', continuos_features)])\n",
    "\n",
    "feature_processing = Pipeline([('feats', feats)])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', feats),\n",
    "    ('classifier', xgb.XGBClassifier(random_state = 21)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = df_base.iloc[:,:-1]\n",
    "y_data = df_base.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:04:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\programming\\anaconda3\\lib\\site-packages\\xgboost-1.4.1-py3.8-win-amd64.egg\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 FeatureUnion(transformer_list=[('continuos_features',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  ColumnSelector(key=[0,\n",
       "                                                                                      1,\n",
       "                                                                                      2,\n",
       "                                                                                      3,\n",
       "                                                                                      4,\n",
       "                                                                                      5,\n",
       "                                                                                      6,\n",
       "                                                                                      7,\n",
       "                                                                                      8,\n",
       "                                                                                      9,\n",
       "                                                                                      10,\n",
       "                                                                                      11,\n",
       "                                                                                      12,\n",
       "                                                                                      13,\n",
       "                                                                                      14,\n",
       "                                                                                      15,\n",
       "                                                                                      16,\n",
       "                                                                                      17,\n",
       "                                                                                      18,\n",
       "                                                                                      19,\n",
       "                                                                                      20,\n",
       "                                                                                      21,\n",
       "                                                                                      22,\n",
       "                                                                                      23,\n",
       "                                                                                      24,\n",
       "                                                                                      25,\n",
       "                                                                                      26,\n",
       "                                                                                      27,\n",
       "                                                                                      28,\n",
       "                                                                                      29, ...]))]))])),\n",
       "                ('classifier',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                               importance_type='gain',\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=6, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=4, num_parallel_tree=1, random_state=21,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               subsample=1, tree_method='exact',\n",
       "                               validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\programming\\anaconda3\\lib\\site-packages\\xgboost-1.4.1-py3.8-win-amd64.egg\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification results:\n",
      "F1_Score: \t93.023%\n",
      "Roc_AUC: \t91.751%\n",
      "Precision: \t95.238%\n",
      "Recall: \t90.909%\n"
     ]
    }
   ],
   "source": [
    "y_predict = pipeline.predict(X_test)\n",
    "y_pred_proba = pipeline.predict_proba(X_test)\n",
    "print(evaluate_results(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds, fscore, roc, precision, recall = evaluate_results(y_test, y_predict, fstr=False)\n",
    "xgbc_score = {\"XGBClassifier\":pd.Series([thresholds,\n",
    "                                         fscore,\n",
    "                                         precision,\n",
    "                                         recall,\n",
    "                                         roc,],\n",
    "                                        index=['Threshold',\n",
    "                                               'F-Score',\n",
    "                                               'ROC_AUC',\n",
    "                                               'Precision',\n",
    "                                               'Recall'\n",
    "                                              ])}\n",
    "df_score = pd.DataFrame(xgbc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGBClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Threshold</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-Score</th>\n",
       "      <td>0.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC_AUC</th>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.917508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           XGBClassifier\n",
       "Threshold            NaN\n",
       "F-Score         0.930233\n",
       "ROC_AUC         0.952381\n",
       "Precision       0.909091\n",
       "Recall          0.917508"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best_Threshold:\t0.148,\n",
      "F1_Score:\t94.382%,\n",
      "Roc_AUC:\t98.401%,\n",
      "Precision:\t93.333%,\n",
      "Recall: \t95.455%\n"
     ]
    }
   ],
   "source": [
    "print(get_metrics(y_test, y_pred_proba[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGBClassifier_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Threshold</th>\n",
       "      <td>0.148428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-Score</th>\n",
       "      <td>0.943820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC_AUC</th>\n",
       "      <td>0.984007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           XGBClassifier_probs\n",
       "Threshold             0.148428\n",
       "F-Score               0.943820\n",
       "ROC_AUC               0.984007\n",
       "Precision             0.933333\n",
       "Recall                0.954545"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds, fscore, roc, precision, recall = get_metrics(y_test, y_pred_proba[:, 1], fstr=False)\n",
    "xgbc_score_prob = {\"XGBClassifier_probs\":pd.Series([thresholds,\n",
    "                                                    fscore,\n",
    "                                                    roc,\n",
    "                                                    precision,\n",
    "                                                    recall,\n",
    "                                                   ],\n",
    "                                                   index=['Threshold',\n",
    "                                                          'F-Score',\n",
    "                                                          'ROC_AUC',\n",
    "                                                          'Precision',\n",
    "                                                          'Recall'\n",
    "                                                         ])}\n",
    "df_score_prob = pd.DataFrame(xgbc_score_prob)\n",
    "df_score_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем выборку на тренировочную и тестовую части и обучаем модель (в примере - градиентный бустинг)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теперь очередь за PU learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представим, что нам неизвестны негативы и часть позитивов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_pu_class_45 = RandomNegativeSamplingPU(new_key_name='class_test', share_of_positive_classes=0.45)\n",
    "add_pu_class_35 = RandomNegativeSamplingPU(new_key_name='class_test', share_of_positive_classes=0.35)\n",
    "add_pu_class_25 = RandomNegativeSamplingPU(new_key_name='class_test', share_of_positive_classes=0.25)\n",
    "add_pu_class_15 = RandomNegativeSamplingPU(new_key_name='class_test', share_of_positive_classes=0.15)\n",
    "add_pu_class_5 = RandomNegativeSamplingPU(new_key_name='class_test', share_of_positive_classes=0.5)\n",
    "\n",
    "sample_train_45, sample_test_45 = add_pu_class_45.fit_transform(df_base.copy())\n",
    "sample_train_35, sample_test_35 = add_pu_class_35.fit_transform(df_base.copy())\n",
    "sample_train_25, sample_test_25 = add_pu_class_25.fit_transform(df_base.copy())\n",
    "sample_train_15, sample_test_15 = add_pu_class_15.fit_transform(df_base.copy())\n",
    "sample_train_5, sample_test_5 = add_pu_class_5.fit_transform(df_base.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_pu_45 = Pipeline([\n",
    "    ('features', feats),\n",
    "    ('classifier', xgb.XGBClassifier(random_state = 21)),\n",
    "])\n",
    "\n",
    "pipeline_pu_35 = Pipeline([\n",
    "    ('features', feats),\n",
    "    ('classifier', xgb.XGBClassifier(random_state = 21)),\n",
    "])\n",
    "\n",
    "pipeline_pu_25 = Pipeline([\n",
    "    ('features', feats),\n",
    "    ('classifier', xgb.XGBClassifier(random_state = 21)),\n",
    "])\n",
    "\n",
    "pipeline_pu_15 = Pipeline([\n",
    "    ('features', feats),\n",
    "    ('classifier', xgb.XGBClassifier(random_state = 21)),\n",
    "])\n",
    "\n",
    "pipeline_pu_5 = Pipeline([\n",
    "    ('features', feats),\n",
    "    ('classifier', xgb.XGBClassifier(random_state = 21)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\programming\\anaconda3\\lib\\site-packages\\xgboost-1.4.1-py3.8-win-amd64.egg\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\programming\\anaconda3\\lib\\site-packages\\xgboost-1.4.1-py3.8-win-amd64.egg\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:04:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:04:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:04:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:04:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:04:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "# X_sample_train = sample_train.iloc[:,:-2]\n",
    "# y_sample_train= sample_train.iloc[:,-2]\n",
    "pipeline_pu_45.fit(sample_train_45.iloc[:,:-2], sample_train_45.iloc[:,-2])\n",
    "y_predict_pu_45 = pipeline_pu_45.predict(sample_test_45.iloc[:,:-2])\n",
    "y_pred_proba_pu_45 = pipeline_pu_45.predict_proba(sample_test_45.iloc[:,:-2])\n",
    "\n",
    "pipeline_pu_35.fit(sample_train_35.iloc[:,:-2], sample_train_35.iloc[:,-2])\n",
    "y_predict_pu_35 = pipeline_pu_35.predict(sample_test_35.iloc[:,:-2])\n",
    "y_pred_proba_pu_35 = pipeline_pu_35.predict_proba(sample_test_35.iloc[:,:-2])\n",
    "\n",
    "pipeline_pu_25.fit(sample_train_25.iloc[:,:-2], sample_train_25.iloc[:,-2])\n",
    "y_predict_pu_25 = pipeline_pu_25.predict(sample_test_25.iloc[:,:-2])\n",
    "y_pred_proba_pu_25 = pipeline_pu_25.predict_proba(sample_test_25.iloc[:,:-2])\n",
    "\n",
    "pipeline_pu_15.fit(sample_train_15.iloc[:,:-2], sample_train_15.iloc[:,-2])\n",
    "y_predict_pu_15 = pipeline_pu_15.predict(sample_test_15.iloc[:,:-2])\n",
    "y_pred_proba_pu_15 = pipeline_pu_15.predict_proba(sample_test_15.iloc[:,:-2])\n",
    "\n",
    "pipeline_pu_5.fit(sample_train_5.iloc[:,:-2], sample_train_5.iloc[:,-2])\n",
    "y_predict_pu_5 = pipeline_pu_5.predict(sample_test_5.iloc[:,:-2])\n",
    "y_pred_proba_pu_5 = pipeline_pu_5.predict_proba(sample_test_5.iloc[:,:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification results:\n",
      "F1_Score: \t92.208%\n",
      "Roc_AUC: \t91.972%\n",
      "Precision: \t86.585%\n",
      "Recall: \t98.611%\n",
      "\n",
      "Classification results:\n",
      "F1_Score: \t91.324%\n",
      "Roc_AUC: \t89.650%\n",
      "Precision: \t86.957%\n",
      "Recall: \t96.154%\n",
      "\n",
      "Classification results:\n",
      "F1_Score: \t85.806%\n",
      "Roc_AUC: \t78.753%\n",
      "Precision: \t75.568%\n",
      "Recall: \t99.254%\n",
      "\n",
      "Classification results:\n",
      "F1_Score: \t89.918%\n",
      "Roc_AUC: \t84.643%\n",
      "Precision: \t85.938%\n",
      "Recall: \t94.286%\n",
      "\n",
      "Classification results:\n",
      "F1_Score: \t90.909%\n",
      "Roc_AUC: \t92.143%\n",
      "Precision: \t83.333%\n",
      "Recall: \t100.000%\n"
     ]
    }
   ],
   "source": [
    "print(f'{evaluate_results(sample_test_45.iloc[:,-2], y_predict_pu_45)}\\n\\n'\n",
    "      f'{evaluate_results(sample_test_35.iloc[:,-2], y_predict_pu_35)}\\n\\n'\n",
    "      f'{evaluate_results(sample_test_25.iloc[:,-2], y_predict_pu_25)}\\n\\n'\n",
    "      f'{evaluate_results(sample_test_15.iloc[:,-2], y_predict_pu_15)}\\n\\n'\n",
    "      f'{evaluate_results(sample_test_5.iloc[:,-2], y_predict_pu_5)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGBClassifier</th>\n",
       "      <th>XGBClassifier_rand_neg_sampl_45</th>\n",
       "      <th>XGBClassifier_rand_neg_sampl_35</th>\n",
       "      <th>XGBClassifier_rand_neg_sampl_25</th>\n",
       "      <th>XGBClassifier_rand_neg_sampl_15</th>\n",
       "      <th>XGBClassifier_rand_neg_sampl_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Threshold</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-Score</th>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.913242</td>\n",
       "      <td>0.858065</td>\n",
       "      <td>0.899183</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC_AUC</th>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.919722</td>\n",
       "      <td>0.896500</td>\n",
       "      <td>0.787531</td>\n",
       "      <td>0.846429</td>\n",
       "      <td>0.921429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.755682</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.917508</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.992537</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           XGBClassifier  XGBClassifier_rand_neg_sampl_45  \\\n",
       "Threshold            NaN                              NaN   \n",
       "F-Score         0.930233                         0.922078   \n",
       "ROC_AUC         0.952381                         0.919722   \n",
       "Precision       0.909091                         0.865854   \n",
       "Recall          0.917508                         0.986111   \n",
       "\n",
       "           XGBClassifier_rand_neg_sampl_35  XGBClassifier_rand_neg_sampl_25  \\\n",
       "Threshold                              NaN                              NaN   \n",
       "F-Score                           0.913242                         0.858065   \n",
       "ROC_AUC                           0.896500                         0.787531   \n",
       "Precision                         0.869565                         0.755682   \n",
       "Recall                            0.961538                         0.992537   \n",
       "\n",
       "           XGBClassifier_rand_neg_sampl_15  XGBClassifier_rand_neg_sampl_5  \n",
       "Threshold                              NaN                             NaN  \n",
       "F-Score                           0.899183                        0.909091  \n",
       "ROC_AUC                           0.846429                        0.921429  \n",
       "Precision                         0.859375                        0.833333  \n",
       "Recall                            0.942857                        1.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds, fscore, roc, precision, recall = evaluate_results(sample_test_45.iloc[:,-2],\n",
    "                                                              y_predict_pu_45,\n",
    "                                                              fstr=False)\n",
    "xgbc_score_pu_45 = {\"XGBClassifier_rand_neg_sampl_45\":\n",
    "                    pd.Series([thresholds,\n",
    "                               fscore,\n",
    "                               roc,\n",
    "                               precision,\n",
    "                               recall,\n",
    "                              ],\n",
    "                              index=['Threshold',\n",
    "                                     'F-Score',\n",
    "                                     'ROC_AUC',\n",
    "                                     'Precision',\n",
    "                                     'Recall'\n",
    "                                    ])}\n",
    "df_score = df_score.join(pd.DataFrame(xgbc_score_pu_45))\n",
    "\n",
    "thresholds, fscore, roc, precision, recall = evaluate_results(sample_test_35.iloc[:,-2],\n",
    "                                                              y_predict_pu_35,\n",
    "                                                              fstr=False)\n",
    "xgbc_score_pu_35 = {\"XGBClassifier_rand_neg_sampl_35\":\n",
    "                    pd.Series([thresholds,\n",
    "                               fscore,\n",
    "                               roc,\n",
    "                               precision,\n",
    "                               recall,\n",
    "                              ],\n",
    "                              index=['Threshold',\n",
    "                                     'F-Score',\n",
    "                                     'ROC_AUC',\n",
    "                                     'Precision',\n",
    "                                     'Recall'\n",
    "                                    ])}\n",
    "df_score = df_score.join(pd.DataFrame(xgbc_score_pu_35))\n",
    "\n",
    "thresholds, fscore, roc, precision, recall = evaluate_results(sample_test_25.iloc[:,-2],\n",
    "                                                              y_predict_pu_25,\n",
    "                                                              fstr=False)\n",
    "xgbc_score_pu_25 = {\"XGBClassifier_rand_neg_sampl_25\":\n",
    "                    pd.Series([thresholds,\n",
    "                               fscore,\n",
    "                               roc,\n",
    "                               precision,\n",
    "                               recall,\n",
    "                              ],\n",
    "                              index=['Threshold',\n",
    "                                     'F-Score',\n",
    "                                     'ROC_AUC',\n",
    "                                     'Precision',\n",
    "                                     'Recall'\n",
    "                                    ])}\n",
    "df_score = df_score.join(pd.DataFrame(xgbc_score_pu_25))\n",
    "\n",
    "thresholds, fscore, roc, precision, recall = evaluate_results(sample_test_15.iloc[:,-2],\n",
    "                                                              y_predict_pu_15,\n",
    "                                                              fstr=False)\n",
    "xgbc_score_pu_15 = {\"XGBClassifier_rand_neg_sampl_15\":\n",
    "                    pd.Series([thresholds,\n",
    "                               fscore,\n",
    "                               roc,\n",
    "                               precision,\n",
    "                               recall,\n",
    "                              ],\n",
    "                              index=['Threshold',\n",
    "                                     'F-Score',\n",
    "                                     'ROC_AUC',\n",
    "                                     'Precision',\n",
    "                                     'Recall'\n",
    "                                    ])}\n",
    "df_score = df_score.join(pd.DataFrame(xgbc_score_pu_15))\n",
    "\n",
    "thresholds, fscore, roc, precision, recall = evaluate_results(sample_test_5.iloc[:,-2],\n",
    "                                                              y_predict_pu_5,\n",
    "                                                              fstr=False)\n",
    "xgbc_score_pu_5 = {\"XGBClassifier_rand_neg_sampl_5\":\n",
    "                    pd.Series([thresholds,\n",
    "                               fscore,\n",
    "                               roc,\n",
    "                               precision,\n",
    "                               recall,\n",
    "                              ],\n",
    "                              index=['Threshold',\n",
    "                                     'F-Score',\n",
    "                                     'ROC_AUC',\n",
    "                                     'Precision',\n",
    "                                     'Recall'\n",
    "                                    ])}\n",
    "df_score = df_score.join(pd.DataFrame(xgbc_score_pu_5))\n",
    "\n",
    "df_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best_Threshold:\t0.826,\n",
      "F1_Score:\t95.890%,\n",
      "Roc_AUC:\t97.944%,\n",
      "Precision:\t94.595%,\n",
      "Recall: \t97.222%\n",
      "\n",
      "Best_Threshold:\t0.886,\n",
      "F1_Score:\t93.137%,\n",
      "Roc_AUC:\t95.754%,\n",
      "Precision:\t95.000%,\n",
      "Recall: \t91.346%\n",
      "\n",
      "Best_Threshold:\t0.946,\n",
      "F1_Score:\t92.473%,\n",
      "Roc_AUC:\t94.508%,\n",
      "Precision:\t88.966%,\n",
      "Recall: \t96.269%\n",
      "\n",
      "Best_Threshold:\t0.735,\n",
      "F1_Score:\t91.954%,\n",
      "Roc_AUC:\t93.952%,\n",
      "Precision:\t92.486%,\n",
      "Recall: \t91.429%\n",
      "\n",
      "Best_Threshold:\t0.933,\n",
      "F1_Score:\t94.444%,\n",
      "Roc_AUC:\t98.831%,\n",
      "Precision:\t96.226%,\n",
      "Recall: \t92.727%\n"
     ]
    }
   ],
   "source": [
    "print(f'{get_metrics(sample_test_45.iloc[:,-2], y_pred_proba_pu_45[:, 1])}\\n\\n'\n",
    "      f'{get_metrics(sample_test_35.iloc[:,-2], y_pred_proba_pu_35[:, 1])}\\n\\n'\n",
    "      f'{get_metrics(sample_test_25.iloc[:,-2], y_pred_proba_pu_25[:, 1])}\\n\\n'\n",
    "      f'{get_metrics(sample_test_15.iloc[:,-2], y_pred_proba_pu_15[:, 1])}\\n\\n'\n",
    "      f'{get_metrics(sample_test_5.iloc[:,-2], y_pred_proba_pu_5[:, 1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGBClassifier_probs</th>\n",
       "      <th>XGBClassifier_probs_rand_neg_sampl_45</th>\n",
       "      <th>XGBClassifier_probs_rand_neg_sampl_35</th>\n",
       "      <th>XGBClassifier_probs_rand_neg_sampl_25</th>\n",
       "      <th>XGBClassifier_probs_rand_neg_sampl_15</th>\n",
       "      <th>XGBClassifier_probs_rand_neg_sampl_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Threshold</th>\n",
       "      <td>0.148428</td>\n",
       "      <td>0.825726</td>\n",
       "      <td>0.886296</td>\n",
       "      <td>0.946048</td>\n",
       "      <td>0.734873</td>\n",
       "      <td>0.933204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-Score</th>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.979444</td>\n",
       "      <td>0.957541</td>\n",
       "      <td>0.945080</td>\n",
       "      <td>0.939524</td>\n",
       "      <td>0.988312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC_AUC</th>\n",
       "      <td>0.984007</td>\n",
       "      <td>0.958904</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>0.924731</td>\n",
       "      <td>0.919540</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.889655</td>\n",
       "      <td>0.924855</td>\n",
       "      <td>0.962264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.913462</td>\n",
       "      <td>0.962687</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.927273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           XGBClassifier_probs  XGBClassifier_probs_rand_neg_sampl_45  \\\n",
       "Threshold             0.148428                               0.825726   \n",
       "F-Score               0.943820                               0.979444   \n",
       "ROC_AUC               0.984007                               0.958904   \n",
       "Precision             0.933333                               0.945946   \n",
       "Recall                0.954545                               0.972222   \n",
       "\n",
       "           XGBClassifier_probs_rand_neg_sampl_35  \\\n",
       "Threshold                               0.886296   \n",
       "F-Score                                 0.957541   \n",
       "ROC_AUC                                 0.931373   \n",
       "Precision                               0.950000   \n",
       "Recall                                  0.913462   \n",
       "\n",
       "           XGBClassifier_probs_rand_neg_sampl_25  \\\n",
       "Threshold                               0.946048   \n",
       "F-Score                                 0.945080   \n",
       "ROC_AUC                                 0.924731   \n",
       "Precision                               0.889655   \n",
       "Recall                                  0.962687   \n",
       "\n",
       "           XGBClassifier_probs_rand_neg_sampl_15  \\\n",
       "Threshold                               0.734873   \n",
       "F-Score                                 0.939524   \n",
       "ROC_AUC                                 0.919540   \n",
       "Precision                               0.924855   \n",
       "Recall                                  0.914286   \n",
       "\n",
       "           XGBClassifier_probs_rand_neg_sampl_5  \n",
       "Threshold                              0.933204  \n",
       "F-Score                                0.988312  \n",
       "ROC_AUC                                0.944444  \n",
       "Precision                              0.962264  \n",
       "Recall                                 0.927273  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds, roc, fscore, precision, recall = get_metrics(sample_test_45.iloc[:,-2],\n",
    "                                                         y_pred_proba_pu_45[:, 1],\n",
    "                                                         fstr=False)\n",
    "xgbc_score_prob_45 = {\"XGBClassifier_probs_rand_neg_sampl_45\":\n",
    "                      pd.Series([thresholds,\n",
    "                                 fscore,\n",
    "                                 roc,\n",
    "                                 precision,\n",
    "                                 recall,\n",
    "                                ],\n",
    "                                index=['Threshold',\n",
    "                                       'F-Score',\n",
    "                                       'ROC_AUC',\n",
    "                                       'Precision',\n",
    "                                       'Recall'\n",
    "                                      ])}\n",
    "df_score_prob = df_score_prob.join(pd.DataFrame(xgbc_score_prob_45))\n",
    "\n",
    "thresholds, roc, fscore, precision, recall = get_metrics(sample_test_35.iloc[:,-2],\n",
    "                                                         y_pred_proba_pu_35[:, 1],\n",
    "                                                         fstr=False)\n",
    "xgbc_score_prob_35 = {\"XGBClassifier_probs_rand_neg_sampl_35\":\n",
    "                      pd.Series([thresholds,\n",
    "                                 fscore,\n",
    "                                 roc,\n",
    "                                 precision,\n",
    "                                 recall,\n",
    "                                ],\n",
    "                                index=['Threshold',\n",
    "                                       'F-Score',\n",
    "                                       'ROC_AUC',\n",
    "                                       'Precision',\n",
    "                                       'Recall'\n",
    "                                      ])}\n",
    "df_score_prob = df_score_prob.join(pd.DataFrame(xgbc_score_prob_35))\n",
    "\n",
    "thresholds, roc, fscore, precision, recall = get_metrics(sample_test_25.iloc[:,-2],\n",
    "                                                         y_pred_proba_pu_25[:, 1],\n",
    "                                                         fstr=False)\n",
    "xgbc_score_prob_25 = {\"XGBClassifier_probs_rand_neg_sampl_25\":\n",
    "                      pd.Series([thresholds,\n",
    "                                 fscore,\n",
    "                                 roc,\n",
    "                                 precision,\n",
    "                                 recall,\n",
    "                                ],\n",
    "                                index=['Threshold',\n",
    "                                       'F-Score',\n",
    "                                       'ROC_AUC',\n",
    "                                       'Precision',\n",
    "                                       'Recall'\n",
    "                                      ])}\n",
    "df_score_prob = df_score_prob.join(pd.DataFrame(xgbc_score_prob_25))\n",
    "\n",
    "thresholds, roc, fscore, precision, recall = get_metrics(sample_test_15.iloc[:,-2],\n",
    "                                                         y_pred_proba_pu_15[:, 1],\n",
    "                                                         fstr=False)\n",
    "xgbc_score_prob_15 = {\"XGBClassifier_probs_rand_neg_sampl_15\":\n",
    "                      pd.Series([thresholds,\n",
    "                                 fscore,\n",
    "                                 roc,\n",
    "                                 precision,\n",
    "                                 recall,\n",
    "                                ],\n",
    "                                index=['Threshold',\n",
    "                                       'F-Score',\n",
    "                                       'ROC_AUC',\n",
    "                                       'Precision',\n",
    "                                       'Recall'\n",
    "                                      ])}\n",
    "df_score_prob = df_score_prob.join(pd.DataFrame(xgbc_score_prob_15))\n",
    "\n",
    "thresholds, roc, fscore, precision, recall = get_metrics(sample_test_5.iloc[:,-2],\n",
    "                                                         y_pred_proba_pu_5[:, 1],\n",
    "                                                         fstr=False)\n",
    "xgbc_score_prob_5 = {\"XGBClassifier_probs_rand_neg_sampl_5\":\n",
    "                      pd.Series([thresholds,\n",
    "                                 fscore,\n",
    "                                 roc,\n",
    "                                 precision,\n",
    "                                 recall,\n",
    "                                ],\n",
    "                                index=['Threshold',\n",
    "                                       'F-Score',\n",
    "                                       'ROC_AUC',\n",
    "                                       'Precision',\n",
    "                                       'Recall'\n",
    "                                      ])}\n",
    "df_score_prob = df_score_prob.join(pd.DataFrame(xgbc_score_prob_5))\n",
    "\n",
    "df_score_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_plot_bar(df_score.loc['F-Score',:].values, df_score_prob.loc['F-Score',:].values, df_score, 'F-Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAGqCAYAAAAbV78MAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAuGklEQVR4nO3deZgcZbn+8e+dBRKECCQRkQAJGHZICElYVAzIvgiIiKCyuCAiEdyOHJSfuHD0iDuiISpGEAQEj6wSBFlEQLKwhJ2cgGEEJIQ9hxgCz++PqsGmM5PpzNRMVb25P9c113RX1XQ/9xCeqX7rrSpFBGZmVn/9yi7AzMyK4YZuZpYIN3Qzs0S4oZuZJcIN3cwsEW7oZmaJcEM3M0uEG7qZWSLc0K0WJD0q6WVJL0l6UtI0Sas3rN9J0p8lvSjpeUmXS9qi6TWGSPqhpPn568zNnw9rsYYbJD0radUOln+8adkkSW0NzyXpM5LukbRIUpuk30naunu/EbNluaFbnewfEasDY4Ftgf8EkLQjcA1wKfA2YBRwF/BXSRvl26wCXAdsCewFDAF2AhYCE7t6Y0kjgXcBAby3G7X/CDgB+AywNrAJ8Adg3268llmHBpRdgNmKiognJU0na+wA3wHOiYgfNWz2FUnbAacCR+RfGwC7RMRL+TZPAd9o8W2PAG4D/gYcCfyu1XoljQY+DewYEbc3rDqv1dcwa4X30K12JI0A9gbmSlqNbE+7owZ7EbB7/ng34OqGZr6ijiBrwOcBe0paZwV+9j1AW1MzNyucG7rVyR8kvQg8RrZ3/VWy4Yt+wBMdbP8E0D4+PrSTbbok6Z3AhsBFETEL+F/g8BV4iW6/t9mKcEO3OjkwItYAJgGbkTXrZ4HXgHU72H5d4On88cJOtmnFkcA1EdH+Wufny9otBQY2/cxA4JUC3tusZW7oVjsRcSMwDfhuRCwCbgUO6WDTD5AdCAW4lmyo5E0r8l6SBuev8+58ds2TwGeBMZLG5JvNB0Y2/ego4O/54+uAEZLGr8h7m60oN3Srqx8Cu0saC5wEHJlPC1xD0lqSvgnsCHwt3/5csqGaSyRtJqmfpKGSTpa0z3Le50DgVWALsoOwY4HNgb+QjasDXAgcLWliPj1xE7KmfwFARDwM/BT4bT6dcRVJgyR9UNJJhfw2zHBDt5qKiAXAOcApEXEzsCfwPrKx6r+TTWt8Z95MiYh/kR0YfQD4E/ACcDvZsM3flvNWRwK/ioj5EfFk+xfwE+BDkgZExHSyPyq/Ap4HrgJ+DUxteJ3P5D9zJvAc2Tj8QcDlPfxVmL1OvmORmVkavIduZpYIn1hkKz1JGwD3dbJ6i4iY35f1mHWXh1zMzBJR2h76sGHDYuTIkWW9vZlZLc2aNevpiBje0brSGvrIkSOZOXNmWW9vZlZLkv7e2TofFDUzS4QbuplZIrps6JLOlvSUpHs6WS9JP85vFnC3pHHFl2lmZl1pZQx9GtkZbud0sn5vYHT+tT3ws/y7mdXcK6+8QltbG4sXLy67lJXOoEGDGDFiBAMHNl/3rXNdNvSIuCm/W0tnDiC7uUAAt0laU9K6EeHLhZrVXFtbG2ussQYjR45EUtnlrDQigoULF9LW1saoUaNa/rkixtDXI7voUbu2fNkyJB0jaaakmQsWLCjgrc2sNy1evJihQ4e6mfcxSQwdOnSFPxkV0dA7+i/d4dlKETE1IsZHxPjhwzucRmlmFeNmXo7u/N6LaOhtwPoNz0cAjxfwumZmtgKKOLHoMuB4SReQHQx93uPnZmkaedKVhb7eo9/et8ttTjvtNM4//3z69+9Pv379OOuss9h+e8+76EiXDV3Sb8lu+TVMUhvZfRwHAkTEFLJrP+8DzAX+Dzi6t4rtkVPf3M2fe77YOsysZbfeeitXXHEFs2fPZtVVV+Xpp59myZIl3X69pUuXMmBAutckbGWWy2FdrA/g04VVZGaWe+KJJxg2bBirrroqAMOGZff8njFjBieccAKLFi1i1VVX5brrrmPgwIF86lOfYubMmQwYMIDvf//77LLLLkybNo0rr7ySxYsXs2jRIi6//HImT57MnDlzWLp0KaeeeioHHHBAmTELk+6fKjOrvT322IOvf/3rbLLJJuy2224ceuih7Ljjjhx66KFceOGFTJgwgRdeeIHBgwfzox/9CIA5c+bwwAMPsMcee/DQQw8B2Z7+3Xffzdprr83JJ5/Mrrvuytlnn81zzz3HxIkT2W233XjTm1bodrOV5FP/zayyVl99dWbNmsXUqVMZPnw4hx56KGeddRbrrrsuEyZMAGDIkCEMGDCAm2++mY985CMAbLbZZmy44YavN/Tdd9+dtddeG4BrrrmGb3/724wdO5ZJkyaxePFi5s9P45L33kM3s0rr378/kyZNYtKkSWy99daceeaZHU7pW969HRr3viOCSy65hE033bRX6i2TG3oqfNDXEvTggw/Sr18/Ro8eDcCdd97J5ptvztVXX82MGTOYMGECL774IoMHD2bnnXfmvPPOY9ddd+Whhx5i/vz5bLrppsyePfsNr7nnnntyxhlncMYZZyCJO+64g2233baMeIWrXUPv7rSpRwcVXIjZSqiVaYZFeumll5g8eTLPPfccAwYM4O1vfztTp07l6KOPZvLkybz88ssMHjyYa6+9luOOO45jjz2WrbfemgEDBjBt2rTXD6Y2OuWUUzjxxBPZZpttiAhGjhzJFVdc0ae5ektpt6AbP358dOcGF91v6Id36+dqswfrPXTrBffffz+bb7552WWstDr6/UuaFRHjO9q+dnvoZmaV8vgd3fu5txU/zONZLmZmiXBDNzNLhIdcrB58jMCsS27oZmXzHysriBt6xXhapiWnQgcNl+futue69XPbVGjg2g3dzFrX3U8TnTnmhmJfbyVXob8tZmbLOu2009hyyy3ZZpttGDt2LH/729/KLqllN9wyk/2O+EyfvZ/30M2ssupwPfSIICLo16/8/ePyKzAz60RH10N/29vexowZM9hpp50YM2YMEydO5MUXX2Tx4sUcffTRbL311my77bZcf/31AEybNo1DDjmE/fffnz322INFixbx0Y9+lAkTJrDtttty6aWXdvr+l150Pid89HA+9eH38953T2DKD/4bgH88Np8Dd9me007+POP2PJzHHn+SL37jB2y16yFs/Z4PcOGl019/jRdeWsRBH/s8W0w6mGO/dBqvvfYar776KkcddRRbbbUVW2+9NT/4wQ8K+X15D936lA/62oroy+uhd+aeu2ZzybW3MGjQYA7fb1feteserLn2UB7934f5+vd+woe/fTyXXHkdd977EHf96QKefuY5JuzzEXbeYRwAt995L/ddfzEbjliXvT50PL+/6s+M2uBt/OMf/+Cee+4B4Lnnnivk9+U9dDOrrCpcD32Hd01izbXWZtDgwbxn7/25Y8ZtAKw7Yn22GZfVcPPtd3DYgXvSv39/1hk+lHfvMI4Zd90HwMSxW7LRhiPo378/hx24JzfffgcbbTCCefPmMXnyZK6++mqGDBlSyO/Le+hmVml9dT30zqYtNr9X+/PBg1dr6b07+vm11hzCXXfdxfTp0znzzDO56KKLOPvsszt9jVa5oZtZ67pzMlN356FTjeuh33bTDTz/7LOsOmgQ10+/kq999yfLbLPzDuM46zeXcOQh+/PMcy9w099mc/opJ/LA3Ee5/c57eWT+P9hwxLpceNk1HPOhg3n6mWdZZfXXOPjgg9l444056qijuv07auSGbmaVVYXroW87cQe+fOInmf/oI+xz4PvZcsy2/OOxNw7RHLT3rtw6627G7P5BJPGdL5/AW98yjAfmPsqO47bmpP/6MXMemMvO24/joL13Yc79czn6iEm89tprAHzrW98q5Pflhm5mlbXddttxyy23LLN82LBh3HbbbcssnzZt2jLLjjrqqDfsAQ8ePJizzjqr5RrWGjqM03/2qzcsW2/9Dfj9dbe+/lwSp5/yWU4/5bNv2G7STuOZtNOyly4fs+Umy3xyKIIPipqZJcJ76Ga20ps+fTonfO4Lb1j2tvU35Ie/+A0HfKCbdzsrgRu6mS1XRHQ4qyQle+65JxdN377sMt6gO7cH9ZCLmXVq0KBBLFy4sFvNxbovIli4cCGDBq3YGXXeQzezTo0YMYK2tjYWLFjQ/Rd57qnu/dzz93f/Pbvhn8++3K2fu1/d/N10kW/QoEGMGDFihV7SDd3MOjVw4EBGjRoF9OSyDd0cg+7jG3jsnUA+D7mYmSXCDd3MLBFu6GZmiXBDNzNLhBu6mVkiWmrokvaS9KCkuZJO6mD9myVdLukuSfdKOrr4Us3MbHm6bOiS+gNnAnsDWwCHSdqiabNPA/dFxBhgEvA9SasUXKuZmS1HK3voE4G5ETEvIpYAFwAHNG0TwBrKzg9eHXgGWFpopWZmtlytNPT1gMcanrflyxr9BNgceByYA5wQEa81v5CkYyTNlDSzR2eemZnZMlpp6B1dlaf5wg57AncCbwPGAj+RtMxN8iJiakSMj4jxw4cPX8FSzcxseVpp6G3A+g3PR5DtiTc6Gvh9ZOYCjwCbFVOimZm1opVrucwARksaBfwD+CDQfPGC+cB7gL9IWgfYFJhXZKFmddCd6508umIX1DPrVJcNPSKWSjoemA70B86OiHslHZuvnwJ8A5gmaQ7ZEM2XIuLpXqzbzMyatHS1xYi4CriqadmUhsePA3sUW5qZma0InylqZpYIN3Qzs0S4oZuZJcIN3cwsEW7oZmaJcEM3M0uEG7qZWSLc0M3MEuGGbmaWCDd0M7NEuKGbmSXCDd3MLBFu6GZmiXBDNzNLhBu6mVki3NDNzBLhhm5mlgg3dDOzRLihm5klwg3dzCwRbuhmZolwQzczS4QbuplZItzQzcwS4YZuZpYIN3Qzs0S4oZuZJcIN3cwsEW7oZmaJcEM3M0uEG7qZWSLc0M3MEuGGbmaWiJYauqS9JD0oaa6kkzrZZpKkOyXdK+nGYss0M7OuDOhqA0n9gTOB3YE2YIakyyLivoZt1gR+CuwVEfMlvaWX6jUzs060soc+EZgbEfMiYglwAXBA0zaHA7+PiPkAEfFUsWWamVlXWmno6wGPNTxvy5c12gRYS9INkmZJOqKjF5J0jKSZkmYuWLCgexWbmVmHWmno6mBZND0fAGwH7AvsCZwiaZNlfihiakSMj4jxw4cPX+Fizcysc12OoZPtka/f8HwE8HgH2zwdEYuARZJuAsYADxVSpZmZdamVPfQZwGhJoyStAnwQuKxpm0uBd0kaIGk1YHvg/mJLNTOz5elyDz0ilko6HpgO9AfOjoh7JR2br58SEfdLuhq4G3gN+EVE3NObhZuZ2Ru1MuRCRFwFXNW0bErT89OB04srzczMVoTPFDUzS4QbuplZItzQzcwS4YZuZpYIN3Qzs0S4oZuZJcIN3cwsEW7oZmaJcEM3M0uEG7qZWSLc0M3MEuGGbmaWCDd0M7NEuKGbmSXCDd3MLBFu6GZmiXBDNzNLhBu6mVki3NDNzBLhhm5mlgg3dDOzRLihm5klwg3dzCwRbuhmZolwQzczS4QbuplZItzQzcwS4YZuZpYIN3Qzs0S4oZuZJcIN3cwsEW7oZmaJcEM3M0tESw1d0l6SHpQ0V9JJy9lugqRXJb2/uBLNzKwVXTZ0Sf2BM4G9gS2AwyRt0cl2/w1ML7pIMzPrWit76BOBuRExLyKWABcAB3Sw3WTgEuCpAuszM7MWtdLQ1wMea3jeli97naT1gIOAKct7IUnHSJopaeaCBQtWtFYzM1uOVhq6OlgWTc9/CHwpIl5d3gtFxNSIGB8R44cPH95iiWZm1ooBLWzTBqzf8HwE8HjTNuOBCyQBDAP2kbQ0Iv5QRJFmZta1Vhr6DGC0pFHAP4APAoc3bhARo9ofS5oGXOFmbmbWt7ps6BGxVNLxZLNX+gNnR8S9ko7N1y933NzMzPpGK3voRMRVwFVNyzps5BFxVM/LMjOzFeUzRc3MEuGGbmaWCDd0M7NEuKGbmSXCDd3MLBFu6GZmiXBDNzNLhBu6mVki3NDNzBLhhm5mlgg3dDOzRLihm5klwg3dzCwRbuhmZolwQzczS4QbuplZItzQzcwS4YZuZpYIN3Qzs0S4oZuZJcIN3cwsEW7oZmaJcEM3M0uEG7qZWSLc0M3MEuGGbmaWCDd0M7NEuKGbmSXCDd3MLBFu6GZmiXBDNzNLhBu6mVki3NDNzBLhhm5mloiWGrqkvSQ9KGmupJM6WP8hSXfnX7dIGlN8qWZmtjxdNnRJ/YEzgb2BLYDDJG3RtNkjwLsjYhvgG8DUogs1M7Pla2UPfSIwNyLmRcQS4ALggMYNIuKWiHg2f3obMKLYMs3MrCutNPT1gMcanrflyzrzMeCPHa2QdIykmZJmLliwoPUqzcysS600dHWwLDrcUNqFrKF/qaP1ETE1IsZHxPjhw4e3XqWZmXVpQAvbtAHrNzwfATzevJGkbYBfAHtHxMJiyjMzs1a1soc+AxgtaZSkVYAPApc1biBpA+D3wEci4qHiyzQzs650uYceEUslHQ9MB/oDZ0fEvZKOzddPAf4fMBT4qSSApRExvvfKNjOzZq0MuRARVwFXNS2b0vD448DHiy3NzMxWhM8UNTNLhBu6mVki3NDNzBLhhm5mlgg3dDOzRLihm5klwg3dzCwRbuhmZolwQzczS4QbuplZItzQzcwS4YZuZpYIN3Qzs0S4oZuZJcIN3cwsEW7oZmaJcEM3M0uEG7qZWSLc0M3MEuGGbmaWCDd0M7NEuKGbmSXCDd3MLBFu6GZmiXBDNzNLhBu6mVki3NDNzBLhhm5mlgg3dDOzRLihm5klwg3dzCwRbuhmZolwQzczS0RLDV3SXpIelDRX0kkdrJekH+fr75Y0rvhSzcxsebps6JL6A2cCewNbAIdJ2qJps72B0fnXMcDPCq7TzMy60Moe+kRgbkTMi4glwAXAAU3bHACcE5nbgDUlrVtwrWZmthwDWthmPeCxhudtwPYtbLMe8ETjRpKOIduDB3hJ0oMrVG0PCIYBT6/wD35NxRfTC5yvEzXIl3I2cL5OdT/fhp2taKWhd/Su0Y1tiIipwNQW3rNwkmZGxPgy3rsvOF99pZwNnK8vtTLk0gas3/B8BPB4N7YxM7Ne1EpDnwGMljRK0irAB4HLmra5DDgin+2yA/B8RDzR/EJmZtZ7uhxyiYilko4HpgP9gbMj4l5Jx+brpwBXAfsAc4H/A47uvZK7rZShnj7kfPWVcjZwvj6jiGWGus3MrIZ8pqiZWSLc0M3MEuGGbmaWiCQbuqR+kj5Qdh1mZn0pyYYeEa8Bx5ddR1+RtLqkcZLWLLuWoqWcDZyvbiTt1fD4zZJ+mV+Q8HxJ65RZGyTa0HN/kvQFSetLWrv9q+yiiiDppw2P3wncB3wPmCNpn9IKK0DK2cD5SiusOP/V8Ph7ZJc32Z/sfJ2zSqmoUUQk+QU80sHXvLLrKijb7IbH1wPj8scbATPLrs/ZnG8lyXdn07o7+7KWjr5auZZLLUXEqLJr6CNDImI2QETMyy93nIqUs4Hz1dFbJH2O7PpVQyQp8m5OBUY8km3oklYDPgdsEBHHSBoNbBoRV5RcWhE2k3Q32T+qkZLWiohnJfUDBpZcW0+lnA2cr+5+DqyRP/412ZUWF0h6K3BnWUW1S/ZMUUkXArOAIyJiK0mDgVsjYmy5lfWcpObLZz4eEa9IGgbsHBG/L6OuInSQ7YmIWJJCNkj7vx2kn69Vko6MiF/3+fsm3NBnRsR4SXdExLb5srsiYkzZtfUGSW+JiKfKrsPMQNLsiOjzW3GWPubTi5bke+UBIGlj4F/lllSMxlk7+ddQ4HZJa9V9Jo+kt0r6maQzJQ2VdKqkOZIuSuEuWJKGSPqWpHMlHd607qed/VwKJP2x7Br6UCl350h2DB34KnA1sL6k84B3AEeVWlFxngb+3rRsPWA22R+wjfq8ouJMA64E3kQ2S+I8YF+y2xxOYdnbH9bNr4CHgUuAj0o6GDg8Iv4F7FBqZQVYzg3iBYztw1LKVsrQR7JDLgD5nusOZP+YbouIFb9NVAVJ+gKwG/DFiJiTL3skhZk9TUNk8yNig4Z1d9b9GEhzBklfJrv09HuBP5XxMb1Ikl4FbqTjPdQdImJwH5dUisZ/x30puT10SZtFxAMNewrtN9rYQNIG7dOo6iwivivpAuAHkh4j+zSSyl/mxmHAc5azrq5WldQvsrOZiYjTJLUBNwGrl1taIe4HPhkRDzevyP+triz+WsabJtfQyaYqHkN2FlezAHbt23J6R0S0AYdI2h/4E7BaySUV5VJJq0fESxHxlfaFkt4OPFRiXUW5nOzf4LXtCyLi15L+CZxRWlXFOZXO//BO7sM6ekU+B71TEfH9/Hsplx5JbshF0iER8TtJG0XEvLLr6Qv5wd+NI+KepuWlTJ3qCylnA+erKklfXd76iPhaX9XSkRQb+uyIGFfWtKEqSfl3kHI2cD7rnhSHXBZKuh4YJan5ZtZExHtLqKkspUyd6iMpZwPnqzRJGwE/Ipt0EcCtwGfLHhVIsaHvC4wDzqXjcfSVSVofv94o5WzgfFV3PnAmcFD+/IPAb4HtS6uIBBt6RCwBbpO0U0QsKLuektV6L6gLKWcD56s6RcS5Dc9/I6n0ezAk19Al/TAiTgTOlrTMXsBKNuRSytSpPpJyNnC+qrte0knABWSfNg4Frmw/UzsinimjqBQPim4XEbMkvbuj9RFxY1/XVLRWp07VUcrZwPnqnq+dpEeWszoiopSztZPbQ4+IWfn31xu3pLWA9SPi7tIKK9YaXW9SWylnA+dLQlXPyk5uD72dpBvITqceQHad4gXAjRGx3D0IM7Ou5Dfr2BcYScOOcdmfQFI4lbozb46IF4D3Ab+KiO3Irn+SDEkbSbpc0gJJT0m6NJ9OVXspZwPnS8DlZBf7G0r2qaT9q1TJDbk0GJBfbvUDwJfLLqaXVHLqVEFSzgbOV3cjImKbsotolvIe+teB6cDciJiR7x0sc8GgmlNEnBsRS/Ov31D/+b3tUs4Gzld3f5S0R9lFNEt2DH1lIOnbwHO8cerUqmR7RqVNnSpCytnA+RLIdxDwG7Kd4lfI5tVHRAwpta5UG7qk7wDfBF4mu9HFGODEfE8hCVWdOlWElLOB8yWQbx5wIDAnKtREU27od0bE2Pwv6YHAZ4HrU72nqJn1HUnTgb3br2tfFSkfFB2Yf98H+G1EPCPV/WzjN6rq1KkipJwNnC8BTwA35PdJff1exWXnS7mhXy7pAbIhl+MkDQcWl1xT0S4nyzQHqNSeQgFSzgbOV3eP5F+r5F+VkOyQC7x+hugLEfGqpNWAIRHxZNl1FUXS3VWcOlWElLOB81nvSHkPHWA9YHdJgxqWNd+nss7+KGmPiLim7EJ6QcrZwPlqLf/E/x/AlsDr/SUiSr3FZbINPb9V1CRgC+AqYG/gZtJq6LcB/yOpUlOnCpJyNnC+ujsPuBDYDzgWOJLs8iKlSnbIRdIcsqmKd0TEGEnrAL+IiP1LLq0wVZ06VYSUs4Hz1Z2kWRGxXePQkqQbI6LDq7z2lWT30IGXI+I1SUslDQGeAmo997UDDwP3pPg/DGlnA+eru1fy709I2hd4HBhRYj1A2g19pqQ1gZ8Ds4CXgNtLrah4lZw6VZCUs4Hz1d03Jb0Z+DxwBjCE7FyXUiXb0CPiuPzhFElXk81wSeV66O0qOXWqIClnA+ertYi4In/4PLBLmbU0Sm4MXdK45a2PiNl9VYuZpamqlxZJsaFfv5zVUfa0oiJVdepUEVLOBs5Xd1W9tEhyQy4RUZmPP32gklOnCpJyNnC+uqvkpUWSux66pA9L+kgHyz8h6fAyaupFQyPil8ArEXFjRHwU2KHsogqScjZwvrprv7TIeOC6qlxaJLmGTnbU+Q8dLL8wX5eSN0ydkrQtFZg6VZCUs4Hz1VpEnATsCIyPiFeA/wMOaF8vafcy6kpuyAXoHxEvNi+MiBckDezoB2qsklOnCpJyNnC+2ouIZxseLwIWNaz+b+BPfV1TigdF7yf7q7moafkawIyI2KycysxsZSHpjojYtq/fN8Uhl18CF0sa2b4gf3xBvi4Zkr4jaYikgZKuk/S0pA+XXVcRUs4GzrcSKGVPObmGHhHfBS4FbpS0UNJC4Ebgiog4vdzqCrdHRLxANpOgDdgE+GK5JRUm5WzgfNYLUhxDJyKmkJ0hujrZsNIyY+qJqOTUqYKknA2cL3WPlvGmyTX0/NrnhwLPAFcAX5S0M/C/wDci4uky6ytYyndlSjkbOF+tSXpfB4ufJ7u65FMR0dH6XpfiQdGLyKZMvQlYC7iH7HZY7wTGRsR+JZZXuKa7Mr0JWKP9rkySdo+IPj/SXpSUs4Hz1TmfpCvJpi22n5k+iewa8JsAX4+Ic0upK8GGfk9EbCVpANAWEW9tWHdX2afm9iVJsyNiude2qauUs4HzVZ2ky4GPR8Q/8+frAD8DPg7cFBFblVFXcgdFgSUAEbGU7BrFjV7t+3JKlfKgZcrZwPmqbmR7M889BWwSEc/w75Oq+lxyY+jACEk/JvsH0/6Y/Pl65ZVVirQ+fr1RytnA+aruL5KuAH6XP38/cFM+tPRcWUWl2NAbp0bNbFrX/NzMrDs+DbyP7NicgF8Dl+R3aCrtAoHJNfSI+HXZNVTIo2UX0IseLbuAXvZo2QX0skfLLqAnIiIkzQSej4hrJa0GrA6UOkU6xYOi7wQ2iohz8ucXA2vnq78ZEX8urbiCdTV1qq/rKVLK2cD5+rqeokn6BHAMsHZEbCxpNDAlIt5Tal0JNvTrgMkRcV/+fA5wFNk0xpMjYq8SyytUVadOFSHlbOB8CeS7E5gI/K39mi2S5kTE1mXWldyQC9m9Q+9reP5wRMwCkPStkmrqLa8Bm3cwdWp74Cagzv/TpJwNnK/u+f4VEUvaz37Np0mXvnec4rTFNRufNJ2xtU7fltLrKjl1qiApZwPnq7sbJZ0MDM6vff47shMYS5XiHvoDkvaNiCsbF0raD3iwpJp6SyWnThUk5WzgfHV3EvAxYA7wSeAq4BelVkSaY+ijya7hcgswO1+8HbATsF9EPFRWbUVT9nmvcerUzfx76lStpZwNnM96R4oNfX2yj3cfIrvjOMC9wPnAhIj4S1m19QZJGwKjG6ZOdXjHpjpKORs4X51JegdwKrAh2UiHyGYzblRmXSkOudwITAG+n5/+335A5hfApsCEEmsrVOPUKWBjsjNhpwClTp0qQsrZwPkS8EuyW+rNokKXFEnxoOh2ZP+A7pC0q6QTgNuBW8mOsKfk08A7gBcAIuJh4C2lVlSclLOB89Xd8xHxx/xSuQvbv8ouKrk99PzGrZ/MG/m1ZBfo2iEi2sqtrFdUcupUQVLOBs5Xd9dLOh34PfCv9oURMbvzH+l9yTV0SWuS3XF7e2Avsjum/FHSCSmdJZprnjp1HBWYOlWQlLOB89Vd+6f98Q3LAti1hFpel+JB0XnAT4EfNoyhj82X/T0iDiuxvEJJ6kc2dWoPsoMy04FfpDCTIOVs4Hypk3RkGdeVSrGhj+hseEXSJyLi531dk5mtXMq6gUdyDX1lUtWpU0VIORs4X+ok3dF+jZc+fV839PpSdhPeZaZOVeFoe0+lnA2cL3Vl7aEnd1B0JfN8RPyx7CJ6ScrZwPlSV8ot9ryHXmOSvg30p2JTp4qQcjZwvtRJ+klEHN/n7+uGXl+Sru9gcUREqVOnipByNnC+upL0ueWtj4jv91UtHXFDT1hZU6f6QsrZwPmqStJX84ftlxG5LH++P3BTRHy8lMJybugJK+vATF9IORs4X9VJugY4uP1iY5LWAH4XJd8RLcVrudi/lXJgpo+knA2cr+o2AJY0PF8CjCynlH/zLJe0pfzxK+Vs4HxVdy5wu6T/IctyEHBOuSW5oaeu7ntBy5NyNnC+SouI0yRdTXYDD4CjI+KOMmsCN/TU/bXsAnpRytnA+ergTuAJ8j4qaYOImF9mQT4oWkNVnzrVEylnA+ere752kiYDXwX+SXYmbPulDbYpsy7vodfTGvn3DqdOlVJRcVLOBs6XihOATat2KQPvoddYVadOFSHlbOB8dZefOLV7+yW6q8J76PVWyalTBUk5Gzhf3c0DbpB0JW+8tEGpQ0pu6PVWyalTBUk5Gzhf3c3Pv1bJvyrBQy41J2k7/j116qYqTJ0qSsrZwPmseG7oNSepP7AODZ+2yp46VZSUs4Hz1Zmk4cB/AFsCg9qXl33xMQ+51FhnU6eAUqdOFSHlbOB8CTgPuBDYDzgWOBJYUGpFeA+91iTNBbav2tSpIqScDZyv7iTNiojtJN3dPvdc0o0R8e4y6/Ieer09BjxfdhG9JOVs4Hx190r+/QlJ+wKPAyNKrAdwQ6+7Sk6dKkjK2cD56u6bkt4MfB44AxhCdg/VUrmh11slp04VJOVs4Hy1lR/sHR0RV5B9Ctml5JJe5zF0M7MVJOn6iKhMI2/nhl5jVZ06VYSUs4Hz1Z2k04A3k810WdS+vOybYPuORfV2HvAAMAr4GvAoMKPMggqUcjZwvrrbieyP1deB7+Vf3y21IryHXmtVnTpVhJSzgfOlrqybYPugaL1VcupUQVLOBs6XuhMAN3RbIZWcOlWQlLOB86WulFvsuaHXVJWnTvVUytnA+VYSpYxl+6BoTUXEq8B7y66jN6ScDZxvJeE9dFtht0j6CRWbOlWQlLOB89WWpH7A+yPiouVsVspNsD3Lpcby22A1ixTm+qacDZyv7iTdFBE7l11HMzf0hJU1daovpJwNnK/qJJ0CvMyyn0CeKa0o3NCTJml2RIwru47ekHI2cL6qk/RIB4sjIjbq82IaeAw9baUcmOkjKWcD56u0iBhVdg0d8SyXtKX88SvlbOB8lSZpNUlfkTQ1fz5a0n5l1+WGnrZa7wV1IeVs4HxV9ytgCdk1XQDagG+WV07GDb2mJPWT9IEuNitl6lRPpZwNnC9X23y5jSPiO+SXOIiIl6nAHykfFK2xqk6dKkLK2cD56k7SLcB7gL9GxDhJGwO/jYiJpdblhl5fVZ06VYSUs4Hz1Z2k3YGvAFsA1wDvAI6KiBtKrcsNvb6qOnWqCClnA+dLgaShwA5kQy23RcTTJZfkhm5m1ipJm0XEA5I6nENf9qUN3NBrTNJqwOeADSLiGEmjgU3zq9zVWsrZwPnqStLUPE8lL23gWS71VsmpUwVJORs4X139Kf/+sYjYpemr9OvUuKHXWyWnThUk5WzgfHX1n/n3i0utohM+9b/elkgaTH7WXT516l/lllSYlLOB89XVwny4ZZSky5pXRkSp14F3Q6+3rwJXA+tLOo986lSpFRUn5WzgfHW1LzAOOBf4Xsm1LMMHRWuuilOnipJyNnC+OpM0PCIWlF1HMzf0Gqr61KmeSDkbOF8C+X4YESdKupwOLjBW9pCLG3oNVX3qVE+knA2cL4F820XELEnv7mh9RNzY1zU18hh6PTVOnZpXaiXFSzkbOF+tRcSs/PvrjVvSWsD6EXF3aYXlPG2xnio9daqHUs4GzpcESTdIGiJpbeAu4FeSvl96XR5yqR9JfyL7dDUW+Evz+rLH8Xoi5WzgfHXP107SHRGxraSPk+2df1XS3RGxTZl1ecilnio9daqHUs4GzpeKAZLWBT4AfLnsYtp5D73Gqjp1qggpZwPnqztJhwCnADdHxHGSNgJOj4iDS63LDb1+qj51qidSzgbOV/d8Vechl3o6N//+3VKr6B0pZwPnS4Kk75BdbOxlsjNixwAnRsRvSq3Le+hpqNLUqaKlnA2cr44k3RkRYyUdBBwIfBa4PiLGlFmXpy3WWFWnThUh5WzgfAkYmH/fh+xeopW4tZ4ber29OSJeAN4H/CoitgN2K7mmoqScDZyv7i6X9AAwHrhO0nBgcck1uaHXXOPUqVrfCaYDKWcD56u1iDgJ2BEYHxGvkN0I+4Byq/JB0br7OjCdbOrUjHzq1MMl11SUlLOB86VgPWB3SYMalp1TVjHgg6JmZitM0leBScAWwFXA3mR/vN5fZl0ecqkxSd/JDzwNlHSdpKclfbjsuoqQcjZwvgS8H3gP8GREHE02bXHVcktyQ6+7PfIDT/uR3YR3E+CL5ZZUmJSzgfPV3csR8RqwVNIQ4Clgo5Jr8hh6zS0zdUpK4T68QNrZwPnqbqakNYGfA7OAl4DbS60IN/S6a5869TJwXFWmThUk5WzgfLUWEcflD6dIuhoYUoUTp3xQtObys/BeiIhXJa1G9g/rybLrKkLK2cD56qizW+u1K/sWe27oNSdpK7Ij7a9PnYqIUqdOFSXlbOB8ddTJrfXalX6LPTf0Gqvq1KkipJwNnM96h2e51Fslp04VJOVs4Hy1JOnDkj7SwfJPSDq8jJoauaHXWyWnThUk5WzgfHX1eeAPHSy/MF9XKs9yqbdKTp0qSMrZwPnqqn9EvNi8MCJekDSwox/oSx5DT4SkkVRk6lTRUs4Gzlcnku4nuyDXoqblawAzImKzcirL63BDr5+qT53qiZSzgfMlkO8LZMcGPhURj+bLRgJnAjdExOnlVeeGXktVnzrVEylnA+erez4ASccC/wmsni96Cfh2RPysvKoybuhmZt0gaXWyHrrMmHpZPMulhqo+daonUs4GzldGTUWSNEjSkZL2J7upxackXSHpR5KGlV6f99DrR9IdwM7Newb59LDr89t91VLK2cD5Esh3EfAK8CZgLeAe4HLgncDYiNivxPI8bbGmKj11qodSzgbOV3dbRMRWkgYAbRHx7nz51ZLuKrMw8JBLXQ2U9KbmhfnUqVVKqKdIKWcD56u7JQARsRR4vGndq31fzhu5odfTL4GL8+lSwOtTpy7I19VZytnA+epuhKQfSzqj4XH78/XKLs5DLjUUEd+V9BJwY36kHSo0daonUs4GzldiaUVpvOvSzKZ1zc/7nA+K1lwVp04VJeVs4HxWPA+51FDVp071RMrZwPnKrq+nJL1T0hENzy+W9Of8q/STpryHXkNVnzrVEylnA+dLIN91wOSIuC9/Pgc4iizvyRGxV4nluaHXkaR7mqZOvbVh3V0RMabE8nok5WzgfAnkmxERExqe/z4i3pc//mtEvKO86jzkUleVnjrVQylnA+eruzUbn7Q389w6fVvKsjzLpZ5GSPoxoIbH5M9LnzrVQylnA+eruwck7RsRVzYulLQf8GBJNf27Dg+51I+kI5e3PiJ+3Ve1FC3lbOB8CeQbDVwB3AK0Xwp4O2AnYL+IeKis2sAN3cysZZLWJ7ud3oeALfPF9wLnAxMi4i9l1QZu6LUk6Z3ARhFxTv78YmDtfPU3I+LPpRXXQylnA+dLIN88YArw/fw4AZLWAb4HbNp4wLQMPihaT1/jjWelbUp2BtupwH+UUVCBUs4Gzld32wEbA3dI2lXSCWT3Sr0V2L7UynBDr6sh7fNgcw9HxKyIuAlYo6yiCpJyNnC+WouIZyPik8AvgGvJ/li9IyLOjIjXyq3ODb2u1mx8UrWpUz20ZuOTxLKB89WapDUlnQUcDewFXAz8sQpniYIbel09IGnf5oVVmTrVQylnA+eru9nAw8D4iLgmIk4EPgJ8U9JvS60MHxStpapPneqJlLOB8yWQb0REtHWy7hMR8fO+rqmR99DraTGwDfAXYGT+dVO+rO4fa1POBs5Xa50183xdqc0cvIdeS1WfOtUTKWcD56t7vqrzHno9VXrqVA+lnA2cz3qR99BrLP+f5QdkF0HaYXkfB+sm5WzgfNY7vIdeQ1WfOtUTKWcD57Pe5T30GsrHKX8K/LBhnHJsvuzvEXFYieX1SMrZwPnqnq/q3NBrqOpTp3oi5WzgfHXPV3Vu6GZmifAYuplZItzQzcwS4YZuZpYIN3Qzs0T8fyHGmteoWFxgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_plot_bar(df_score.loc['ROC_AUC',:].values, df_score_prob.loc['ROC_AUC',:].values, df_score, 'ROC_AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_plot_bar(df_score.loc['Precision',:].values, df_score_prob.loc['Precision',:].values, df_score, 'Precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAGqCAYAAAAbV78MAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAse0lEQVR4nO3debxe87n38c83A4khIkNV7ZDQoFpTJKSto6Hm4aCT0mppVVXlQYdTHTzU0VOnhtPW0EgVpRTFaYkQQw1VPDJKzHJC2WhFCOXQCNfzx7223tnZw53ste+11i/f9+u1X3vfa6299/WNuLLuta61liICMzOrvj5FF2BmZvlwQzczS4QbuplZItzQzcwS4YZuZpYIN3Qzs0S4oZv1kKQ7JB2RfX2YpLuLrslWTW7olhxJT0l6Q9Jrkv4q6WJJaxVdl1lvc0O3VO0XEWsB2wDbAt8tthyz3ueGbkmLiL8C06g1diSNl3SPpMWSHpA0oW1bSUMkXSTpOUkvS/p9tnxdSVMkLcyWT5HU0vw0Zl1zQ7ekZY13L2C+pA2AG4BTgSHAt4BrJA3PNr8UWAP4IPAe4L+y5X2Ai4CNgA2BN4BzmpXBrFH9ii7ArJf8XlIAawF/BE4CvgpMjYip2Ta3SJoB7C3pZmqNf2hEvJytvxMgIhYB17T9YEk/Am5vTgyzxnkP3VJ1QESsDUwANgeGUdvD/nR2uGWxpMXAjsD6wAjgpbpm/i5Ja0g6X9JfJL0K3AUMltS3SVnMGuKGbkmLiDuBi4EzgGeASyNicN3HmhFxWrZuiKTBHfyYbwKbATtExCBgp2y5ej2A2QpwQ7dVwU+B3YC7gf0k7SGpr6QBkiZIaomI54EbgfOyk6D9JbU17rWpHTdfLGkItcM3ZqXjhm7Ji4iFwCXAccD+wPeAhdT2yr/NP/8/OBR4C3gUeCHbHmr/IAwEXgTuA25qSuFmK0h+wIWZWRq8h25mlgg3dDOzRLihm5klwg3dzCwRhV0pOmzYsBg5cmRRv97MrJJmzpz5YkQM72hdYQ195MiRzJgxo6hfb2ZWSZL+0tk6H3IxM0uEG7qZWSLc0M3MEuHb55pZp9566y1aW1t58803iy5llTNgwABaWlro379/w9/jhm5mnWptbWXttddm5MiRSL65ZLNEBIsWLaK1tZVRo0Y1/H0+5GJmnXrzzTcZOnSom3mTSWLo0KEr/M6o24Yu6UJJL0h6sJP1kvRzSfMlzZU0ZoUqMLNSczMvxsr8uTeyh34xsGcX6/cCRmcfRwK/WOEqzMysx7o9hh4Rd0ka2cUm+wOXRO0+vPdJGixp/eyBAWaWkJEn3JDrz3vqtH263eZHP/oRl19+OX379qVPnz6cf/757LDDDrnWkYo8TopuQO1BAW1as2XLNXRJR1Lbi2fDDTfM4VebWcruvfdepkyZwqxZs1h99dV58cUXWbJkyUr/vKVLl9KvX8dtb27r4pX6mVu1DF7pevKWR0Pv6EBPh0/NiIjJwGSAsWPH+skalpyV2YNtZC91VfX8888zbNgwVl99dQCGDRsGwPTp0zn22GN5/fXXWX311bntttvo378/X/va15gxYwb9+vXjrLPOYuedd+biiy/mhhtu4M033+T111/n+uuvZ+LEicybN4+lS5dy8skns//++xcZMzd5NPRWak9Mb9MCPJfDz10lrexbWjcFS9Huu+/OKaecwqabbsquu+7KQQcdxIc//GEOOuggrrzySsaNG8err77KwIED+dnPfgbAvHnzePTRR9l99915/PHHgdqe/ty5cxkyZAjf+9732GWXXbjwwgtZvHgx22+/PbvuumuRMXOTx9jidcAXsmmX8cArPn5uZnlYa621mDlzJpMnT2b48OEcdNBBnH/++ay//vqMGzcOgEGDBtGvXz/uvvtuDj30UAA233xzNtpoo3cb+m677caQIUMAuPnmmznttNPYZpttmDBhAm+++SZPP/10MQFz1u0euqTfAhOAYZJaqT3xvD9AREwCpgJ7A/OB/wUO761izWzV07dvXyZMmMCECRPYcsstOffcczsc6evq+chrrrnmMttdc801bLbZZstss7LH0MukkSmXg7tZH8DXc6vIVs7J66zk972Sbx1mOXrsscfo06cPo0ePBmDOnDl84AMf4KabbmL69OmMGzeOv//97wwcOJCddtqJyy67jF122YXHH3+cp59+ms0224xZs2Yt8zP32GMPzj77bM4++2wkMXv2bLbddtsi4uXOl/6bWcOafa7mtddeY+LEiSxevJh+/frx/ve/n8mTJ3P44YczceJE3njjDQYOHMitt97K0UcfzVFHHcWWW25Jv379uPjii989mVrvxBNP5LjjjmOrrbYiIhg5ciRTpkxpaq7e4oZuVjS/u+rUdtttxz333LPc8mHDhnHfffctt/ziiy9ebtlhhx3GYYcd9u7rgQMHcv755+dZZmm4oVtTeYrHrPesOg3de0FmljjfbdHMLBGrzh66mfVICpfGp8576GZmiXBDNzNLhA+5mFnDtrpgo3x/oIcOcuWGbmalVvr7oT83u9NVd9wzgzMmXcKUS36+/Mr35X91qhu6mZVWM++HvrIigoigT5/ij2BXrqGv9IUpA3IuxMx6rou9W963beH3Q//DVZfzx5umsGTJEp595i/sfcCnOOr47/DsM0/z9S98mnEf3pHHZ/2Z3194JudcdCU33n4PkvjB//kyB+2/BwCvvvY6B375mzz2P0+x0w5jOO/H3yUi+PJhhzFjxgwk8aUvfYnjjz++x3+clWvotoryhWGrpDLcD/3BB2Zxza33MGDAQA7Zdxf+ZZfdGTxkKE/9zxOccuY5fP60Y7jmhtuY89DjPHDLFbz40mLG7X0oO40fA8D9cx7i4duvZqOW9dnzc8dw7dQ/MmrD9/Hss8/y4IMPArB48eJc/ryKf49gZtaJMtwPffy/TGDwukMYMHAgH99rP2ZPr91DZv2WEWw1plbD3ffP5uAD9qBv376sN3woHxs/hukPPAzA9tt8kI03aqFv374cfMAe3H3/bDbesIUFCxYwceJEbrrpJgYNGpTLn5f30M2s1Iq+H3r739X2euDANRr63R19/7qDB/HAAw8wbdo0zj33XK666iouvPDCTn9Go9zQzaxhc4/4ywp/z1Z9nlzp31eG+6Hfd9cdvPLyy6w+YAC3T7uBH55xznLb7DR+DOf/5hq++On9eGnxq9z1/2Zx+onH8ej8p7h/zkM8+fSzbNSyPldedzNHfu6TvPjSy6y21jt88pOfZJNNNlnmbpA94YZuZqVVhvuhb7v9eL5/3Fd5+qkn2fuAT/HBrbfl2WeWPURz4F67cO/MuWy922eRxE++fyzvfc8wHp3/FB8esyUn/MfPmffofHbaYQwH7rUz8x6Zz+FfmMA777wDwI9//ONc/rzc0M2stMpwP/R1hw7j9F9ctMyyDUZsyLW33fvua0mcfuLxnH7ispMqEz4ylgkfGbvcz9z6g5su984hDz4pamaWCO+hm9kqb9q0aRz7jW8ts+x9Izbipxf8hv0/c0hBVa04N3Qz61JEdDhVkpI99tiDq6aV6HYCdD050xkfcjGzTg0YMIBFixatVHOxlRcRLFq0iAEDVuwSd++hm1mnWlpaaG1tZeHChfzt5TdW6mc8ooUr98tfeWTlvm8llS3fgAEDaGlpWaEf6YZuZp3q378/o0aNAmCvlb6P0koeg27ybRtSyOdDLmZmiXBDNzNLhBu6mVki3NDNzBLhhm5mlgg3dDOzRLihm5klwg3dzCwRDTV0SXtKekzSfEkndLB+HUnXS3pA0kOSDs+/VDMz60q3DV1SX+BcYC9gC+BgSVu02+zrwMMRsTUwAThT0mo512pmZl1oZA99e2B+RCyIiCXAFcD+7bYJYG3Vbsm2FvASsDTXSs3MrEuNNPQNgGfqXrdmy+qdA3wAeA6YBxwbEe+0/0GSjpQ0Q9KMhQtX8oY2ZmbWoUYaekc3Qm5/L809gDnA+4BtgHMkDVrumyImR8TYiBg7fPjwFSzVzMy60khDbwVG1L1uobYnXu9w4NqomQ88CWyeT4lmZtaIRhr6dGC0pFHZic7PAte12+Zp4OMAktYDNgMW5FmomZl1rdv7oUfEUknHANOAvsCFEfGQpKOy9ZOAfwculjSP2iGa70TEi71Yt5mZtdPQAy4iYiowtd2ySXVfPwfsnm9pZma2InylqJlZItzQzcwS4YZuZpYIN3Qzs0S4oZuZJcIN3cwsEW7oZmaJcEM3M0uEG7qZWSLc0M3MEuGGbmaWCDd0M7NEuKGbmSXCDd3MLBFu6GZmiXBDNzNLhBu6mVki3NDNzBLhhm5mlgg3dDOzRLihm5klwg3dzCwRbuhmZolwQzczS4QbuplZItzQzcwS4YZuZpYIN3Qzs0S4oZuZJcIN3cwsEW7oZmaJcEM3M0tEQw1d0p6SHpM0X9IJnWwzQdIcSQ9JujPfMs3MrDv9uttAUl/gXGA3oBWYLum6iHi4bpvBwHnAnhHxtKT39FK9ZmbWiUb20LcH5kfEgohYAlwB7N9um0OAayPiaYCIeCHfMs3MrDuNNPQNgGfqXrdmy+ptCqwr6Q5JMyV9oaMfJOlISTMkzVi4cOHKVWxmZh1qpKGrg2XR7nU/YDtgH2AP4ERJmy73TRGTI2JsRIwdPnz4ChdrZmad6/YYOrU98hF1r1uA5zrY5sWIeB14XdJdwNbA47lUaWZm3WpkD306MFrSKEmrAZ8Frmu3zR+Af5HUT9IawA7AI/mWamZmXel2Dz0ilko6BpgG9AUujIiHJB2VrZ8UEY9IugmYC7wDXBARD/Zm4WZmtqxGDrkQEVOBqe2WTWr3+nTg9PxKMzOzFeErRc3MEuGGbmaWCDd0M7NEuKGbmSXCDd3MLBFu6GZmiXBDNzNLhBu6mVki3NDNzBLhhm5mlgg3dDOzRLihm5klwg3dzCwRbuhmZolwQzczS4QbuplZItzQzcwS4YZuZpYIN3Qzs0S4oZuZJcIN3cwsEW7oZmaJcEM3M0uEG7qZWSLc0M3MEuGGbmaWCDd0M7NEuKGbmSXCDd3MLBFu6GZmiXBDNzNLhBu6mVki3NDNzBLRUEOXtKekxyTNl3RCF9uNk/S2pE/lV6KZmTWi24YuqS9wLrAXsAVwsKQtOtnuP4FpeRdpZmbda2QPfXtgfkQsiIglwBXA/h1sNxG4Bnghx/rMzKxBjTT0DYBn6l63ZsveJWkD4EBgUlc/SNKRkmZImrFw4cIVrdXMzLrQSENXB8ui3eufAt+JiLe7+kERMTkixkbE2OHDhzdYopmZNaJfA9u0AiPqXrcAz7XbZixwhSSAYcDekpZGxO/zKNLMzLrXSEOfDoyWNAp4FvgscEj9BhExqu1rSRcDU9zMzcyaq9uGHhFLJR1DbXqlL3BhRDwk6ahsfZfHzc3MrDka2UMnIqYCU9st67CRR8RhPS/LzMxWlK8UNTNLhBu6mVki3NDNzBLhhm5mlgg3dDOzRLihm5klwg3dzCwRbuhmZolwQzczS4QbuplZItzQzcwS4YZuZpYIN3Qzs0S4oZuZJcIN3cwsEW7oZmaJcEM3M0uEG7qZWSLc0M3MEuGGbmaWCDd0M7NEuKGbmSXCDd3MLBFu6GZmiXBDNzNLhBu6mVki3NDNzBLhhm5mlgg3dDOzRLihm5klwg3dzCwRbuhmZoloqKFL2lPSY5LmSzqhg/WfkzQ3+7hH0tb5l2pmZl3ptqFL6gucC+wFbAEcLGmLdps9CXwsIrYC/h2YnHehZmbWtUb20LcH5kfEgohYAlwB7F+/QUTcExEvZy/vA1ryLdPMzLrTSEPfAHim7nVrtqwzXwZu7GiFpCMlzZA0Y+HChY1XaWZm3WqkoauDZdHhhtLO1Br6dzpaHxGTI2JsRIwdPnx441WamVm3+jWwTSswou51C/Bc+40kbQVcAOwVEYvyKc/MzBrVyB76dGC0pFGSVgM+C1xXv4GkDYFrgUMj4vH8yzQzs+50u4ceEUslHQNMA/oCF0bEQ5KOytZPAv4vMBQ4TxLA0ogY23tlm5lZe40cciEipgJT2y2bVPf1EcAR+ZZmZmYrwleKmpklwg3dzCwRbuhmZolwQzczS4QbuplZItzQzcwS4YZuZpYIN3Qzs0S4oZuZJcIN3cwsEW7oZmaJcEM3M0uEG7qZWSLc0M3MEuGGbmaWCDd0M7NEuKGbmSXCDd3MLBFu6GZmiXBDNzNLhBu6mVki3NDNzBLhhm5mlgg3dDOzRLihm5klwg3dzCwRbuhmZolwQzczS4QbuplZItzQzcwS4YZuZpYIN3Qzs0S4oZuZJaKhhi5pT0mPSZov6YQO1kvSz7P1cyWNyb9UMzPrSrcNXVJf4FxgL2AL4GBJW7TbbC9gdPZxJPCLnOs0M7NuNLKHvj0wPyIWRMQS4Apg/3bb7A9cEjX3AYMlrZ9zrWZm1oV+DWyzAfBM3etWYIcGttkAeL5+I0lHUtuDB3hN0mMrVG0PCIYBL67wN/5Q+RfTC5yvExXIl3I2cL5OrXy+jTpb0UhD7+i3xkpsQ0RMBiY38DtzJ2lGRIwt4nc3g/NVV8rZwPmaqZFDLq3AiLrXLcBzK7GNmZn1okYa+nRgtKRRklYDPgtc126b64AvZNMu44FXIuL59j/IzMx6T7eHXCJiqaRjgGlAX+DCiHhI0lHZ+knAVGBvYD7wv8DhvVfySivkUE8TOV91pZwNnK9pFLHcoW4zM6sgXylqZpYIN3Qzs0S4oZuZJSLJhi6pj6TPFF2HmVkzJdnQI+Id4Jii62gWSWtJGiNpcNG15C3lbOB8VSNpz7qv15H0q+yGhJdLWq/I2iDRhp65RdK3JI2QNKTto+ii8iDpvLqvdwQeBs4E5knau7DCcpByNnC+wgrLz3/UfX0mtdub7Eftep3zC6moXkQk+QE82cHHgqLryinbrLqvbwfGZF9vDMwouj5nc75VJN+cduvmNLOWjj4auZdLJUXEqKJraJJBETELICIWZLc7TkXK2cD5qug9kr5B7f5VgyQpsm5OCY54JNvQJa0BfAPYMCKOlDQa2CwiphRcWh42lzSX2l+qkZLWjYiXJfUB+hdcW0+lnA2cr+p+Caydff1randaXCjpvcCcoopqk+yVopKuBGYCX4iID0kaCNwbEdsUW1nPSWp/+8znIuItScOAnSLi2iLqykMH2Z6PiCUpZIO0/9tB+vkaJemLEfHrpv/ehBv6jIgYK2l2RGybLXsgIrYuurbeIOk9EfFC0XWYGUiaFRFNfxRn4cd8etGSbK88ACRtAvyj2JLyUT+1k30MBe6XtG7VJ3kkvVfSLySdK2mopJMlzZN0VQpPwZI0SNKPJV0q6ZB2687r7PtSIOnGomtookKezpHsMXTgJOAmYISky4CPAocVWlF+XgT+0m7ZBsAsav+Abdz0ivJzMXADsCa1KYnLgH2oPeZwEss//rBqLgKeAK4BviTpk8AhEfEPYHyhleWgiwfEC9imiaUUrZBDH8kecgHI9lzHU/vLdF9ErPhjokpI0reAXYFvR8S8bNmTKUz2tDtE9nREbFi3bk7Vz4G0zyDp+9RuPf2vwC1FvE3Pk6S3gTvpeA91fEQMbHJJhaj/e9xMye2hS9o8Ih6t21Noe9DGhpI2bBujqrKIOEPSFcB/SXqG2ruRVP5lrj8MeEkX66pqdUl9onY1MxHxI0mtwF3AWsWWlotHgK9GxBPtV2R/V1cVfy7ilybX0KmNKh5J7Squ9gLYpbnl9I6IaAU+LWk/4BZgjYJLyssfJK0VEa9FxA/aFkp6P/B4gXXl5XpqfwdvbVsQEb+W9Dfg7MKqys/JdP4P78Qm1tErshn0TkXEWdnnQm49ktwhF0mfjojfSdo4IhYUXU8zZCd/N4mIB9stL2R0qhlSzgbOV1aSTupqfUT8sFm1dCTFhj4rIsYUNTZUJin/GaScDZzPVk6Kh1wWSbodGCWp/cOsiYh/LaCmohQyOtUkKWcD5ys1SRsDP6M2dBHAvcDxRR8VSLGh7wOMAS6l4+Poq5K03n4tK+Vs4HxldzlwLnBg9vqzwG+BHQqriAQbekQsAe6T9JGIWFh0PQWr9F5QN1LOBs5XdoqIS+te/0ZS4c9gSK6hS/ppRBwHXChpub2AVeyQSyGjU02ScjZwvrK7XdIJwBXU3m0cBNzQdqV2RLxURFEpnhTdLiJmSvpYR+sj4s5m15S3RkenqijlbOB8Vc/XRtKTXayOiCjkau3k9tAjYmb2+d3GLWldYEREzC2ssHyt3f0mlZVyNnC+JJT1quzk9tDbSLqD2uXU/ajdp3ghcGdEdLkHYWbWnexhHfsAI6nbMS76HUgKl1J3Zp2IeBX4BHBRRGxH7f4nyZC0saTrJS2U9IKkP2TjVJWXcjZwvgRcT+1mf0OpvStp+yhUcodc6vTLbrf6GeD7RRfTS0o5OpWTlLOB81VdS0RsVXQR7aW8h34KMA2YHxHTs72D5W4YVHGKiEsjYmn28RuqP9/bJuVs4HxVd6Ok3Ysuor1kj6GvCiSdBixm2dGp1antGRU2OpWHlLOB8yWQ70DgN9R2it+iNlcfETGo0LpSbeiSfgKcCrxB7UEXWwPHZXsKSSjr6FQeUs4GzpdAvgXAAcC8KFETTbmhz4mIbbJ/SQ8AjgduT/WZombWPJKmAXu13de+LFI+Kdo/+7w38NuIeEmq+tXGyyrr6FQeUs4GzpeA54E7suekvvus4qLzpdzQr5f0KLVDLkdLGg68WXBNebueWqZ5QKn2FHKQcjZwvqp7MvtYLfsohWQPucC7V4i+GhFvS1oDGBQRfy26rrxImlvG0ak8pJwNnM96R8p76AAbALtJGlC3rP1zKqvsRkm7R8TNRRfSC1LOBs5Xadk7/n8DPgi8218iotBHXCbb0LNHRU0AtgCmAnsBd5NWQ78P+G9JpRqdyknK2cD5qu4y4EpgX+Ao4IvUbi9SqGQPuUiaR21UcXZEbC1pPeCCiNiv4NJyU9bRqTyknA2cr+okzYyI7eoPLUm6MyI6vMtrsyS7hw68ERHvSFoqaRDwAlDp2dcOPAE8mOL/MKSdDZyv6t7KPj8vaR/gOaClwHqAtBv6DEmDgV8CM4HXgPsLrSh/pRydyknK2cD5qu5USesA3wTOBgZRu9alUMk29Ig4OvtykqSbqE24pHI/9DalHJ3KScrZwPkqLSKmZF++AuxcZC31kjuGLmlMV+sjYlazajGzNJX11iIpNvTbu1gdRY8V5amso1N5SDkbOF/VlfXWIskdcomI0rz9aYJSjk7lJOVs4HxVV8pbiyR3P3RJn5d0aAfLvyLpkCJq6kVDI+JXwFsRcWdEfAkYX3RROUk5Gzhf1bXdWmQscFtZbi2SXEOndtb59x0svzJbl5JlRqckbUsJRqdyknI2cL5Ki4gTgA8DYyPiLeB/gf3b1kvarYi6kjvkAvSNiL+3XxgRr0rq39E3VFgpR6dyknI2cL7Ki4iX675+HXi9bvV/Arc0u6YUT4o+Qu1fzdfbLV8bmB4RmxdTmZmtKiTNjohtm/17Uzzk8ivgakkj2xZkX1+RrUuGpJ9IGiSpv6TbJL0o6fNF15WHlLOB860CCtlTTq6hR8QZwB+AOyUtkrQIuBOYEhGnF1td7naPiFepTRK0ApsC3y62pNyknA2cz3pBisfQiYhJ1K4QXYvaYaXljqknopSjUzlJORs4X+qeKuKXJtfQs3ufHwS8BEwBvi1pJ+B/gH+PiBeLrC9nKT+VKeVs4HyVJukTHSx+hdrdJV+IiI7W97oUT4peRW1kak1gXeBBao/D2hHYJiL2LbC83LV7KtOawNptT2WStFtENP1Me15SzgbOV+V8km6gNrbYdmX6BGr3gN8UOCUiLi2krgQb+oMR8SFJ/YDWiHhv3boHir40t5kkzYqILu9tU1UpZwPnKztJ1wNHRMTfstfrAb8AjgDuiogPFVFXcidFgSUAEbGU2j2K673d/HIKlfJBy5SzgfOV3ci2Zp55Adg0Il7inxdVNV1yx9CBFkk/p/YXpu1rstcbFFdWIdJ6+7WslLOB85XdnyRNAX6Xvf4UcFd2aGlxUUWl2NDrR6NmtFvX/rWZ2cr4OvAJaufmBPwauCZ7QlNhNwhMrqFHxK+LrqFEniq6gF70VNEF9LKnii6glz1VdAE9EREhaQbwSkTcKmkNYC2g0BHpFE+K7ghsHBGXZK+vBoZkq0+NiD8WVlzOuhudanY9eUo5Gzhfs+vJm6SvAEcCQyJiE0mjgUkR8fFC60qwod8GTIyIh7PX84DDqI0xfi8i9iywvFyVdXQqDylnA+dLIN8cYHvg/7Xds0XSvIjYssi6kjvkQu3ZoQ/XvX4iImYCSPpxQTX1lneAD3QwOrUDcBdQ5f9pUs4Gzlf1fP+IiCVtV79mY9KF7x2nOLY4uP5Fuyu21mtuKb2ulKNTOUk5Gzhf1d0p6XvAwOze57+jdgFjoVLcQ39U0j4RcUP9Qkn7Ao8VVFNvKeXoVE5SzgbOV3UnAF8G5gFfBaYCFxRaEWkeQx9N7R4u9wCzssXbAR8B9o2Ix4uqLW+qvd+rH526m3+OTlVaytnA+ax3pNjQR1B7e/c5ak8cB3gIuBwYFxF/Kqq23iBpI2B03ehUh09sqqKUs4HzVZmkjwInAxtRO9IhatOMGxdZV4qHXO4EJgFnZZf/t52QuQDYDBhXYG25qh+dAjahdiXsJKDQ0ak8pJwNnC8Bv6L2SL2ZlOiWIimeFN2O2l+g2ZJ2kXQscD9wL7Uz7Cn5OvBR4FWAiHgCeE+hFeUn5WzgfFX3SkTcmN0qd1HbR9FFJbeHnj249atZI7+V2g26xkdEa7GV9YpSjk7lJOVs4HxVd7uk04FrgX+0LYyIWZ1/S+9LrqFLGkztids7AHtSe2LKjZKOTekq0Uz70amjKcHoVE5SzgbOV3Vt7/bH1i0LYJcCanlXiidFFwDnAT+tO4a+TbbsLxFxcIHl5UpSH2qjU7tTOykzDbgghUmClLOB86VO0heLuK9Uig29pbPDK5K+EhG/bHZNZrZqKeoBHsk19FVJWUen8pByNnC+1Ema3XaPl6b+Xjf06lLtIbzLjU6V4Wx7T6WcDZwvdUXtoSd3UnQV80pE3Fh0Eb0k5WzgfKkr5BF73kOvMEmnAX0p2ehUHlLOBs6XOknnRMQxTf+9bujVJen2DhZHRBQ6OpWHlLOB81WVpG90tT4izmpWLR1xQ09YUaNTzZByNnC+spJ0UvZl221Erste7wfcFRFHFFJYxg09YUWdmGmGlLOB85WdpJuBT7bdbEzS2sDvouAnoqV4Lxf7p0JOzDRJytnA+cpuQ2BJ3eslwMhiSvknT7mkLeW3XylnA+cru0uB+yX9N7UsBwKXFFuSG3rqqr4X1JWUs4HzlVpE/EjSTdQe4AFweETMLrImcENP3Z+LLqAXpZwNnK8K5gDPk/VRSRtGxNNFFuSTohVU9tGpnkg5Gzhf1fO1kTQROAn4G7UrYdtubbBVkXV5D72a1s4+dzg6VUhF+Uk5GzhfKo4FNivbrQy8h15hZR2dykPK2cD5qi67cGq3tlt0l4X30KutlKNTOUk5Gzhf1S0A7pB0A8ve2qDQQ0pu6NVWytGpnKScDZyv6p7OPlbLPkrBh1wqTtJ2/HN06q4yjE7lJeVs4HyWPzf0ipPUF1iPundbRY9O5SXlbOB8VSZpOPBvwAeBAW3Li775mA+5VFhno1NAoaNTeUg5GzhfAi4DrgT2BY4CvggsLLQivIdeaZLmAzuUbXQqDylnA+erOkkzI2I7SXPbZs8l3RkRHyuyLu+hV9szwCtFF9FLUs4Gzld1b2Wfn5e0D/Ac0FJgPYAbetWVcnQqJylnA+erulMlrQN8EzgbGETtGaqFckOvtlKOTuUk5WzgfJWVnewdHRFTqL0L2bngkt7lY+hmZitI0u0RUZpG3sYNvcLKOjqVh5SzgfNVnaQfAetQm3R5vW150Q/B9hOLqu0y4FFgFPBD4ClgepEF5SjlbOB8VfcRav9YnQKcmX2cUWhFeA+90so6OpWHlLOB86WuqIdg+6RotZVydConKWcD50vdsYAbuq2QUo5O5STlbOB8qSvkEXtu6BVV5tGpnko5GzjfKqKQY9k+KVpREfE28K9F19EbUs4GzreK8B66rbB7JJ1DyUancpJyNnC+ypLUB/hURFzVxWaFPATbUy4Vlj0Gq71IYdY35WzgfFUn6a6I2KnoOtpzQ09YUaNTzZByNnC+spN0IvAGy78DeamwonBDT5qkWRExpug6ekPK2cD5yk7Skx0sjojYuOnF1PEx9LQVcmKmSVLOBs5XahExqugaOuIpl7Sl/PYr5WzgfKUmaQ1JP5A0OXs9WtK+Rdflhp62Su8FdSPlbOB8ZXcRsITaPV0AWoFTiyunxg29oiT1kfSZbjYrZHSqp1LOBs6XqWy+zCYR8ROyWxxExBuU4B8pnxStsLKOTuUh5WzgfFUn6R7g48CfI2KMpE2A30bE9oXW5YZeXWUdncpDytnA+apO0m7AD4AtgJuBjwKHRcQdhdblhl5dZR2dykPK2cD5UiBpKDCe2qGW+yLixYJLckM3M2uUpM0j4lFJHc7QF31rAzf0CpO0BvANYMOIOFLSaGCz7C53lZZyNnC+qpI0OctTylsbeMql2ko5OpWTlLOB81XVLdnnL0fEzu0+Cr9PjRt6tZVydConKWcD56uq72afry60ik740v9qWyJpINlVd9no1D+KLSk3KWcD56uqRdnhllGSrmu/MiIKvQ+8G3q1nQTcBIyQdBnZ6FShFeUn5WzgfFW1DzAGuBQ4s+BaluOTohVXxtGpvKScDZyvyiQNj4iFRdfRnht6BZV9dKonUs4GzpdAvp9GxHGSrqeDG4wVfcjFDb2Cyj461RMpZwPnSyDfdhExU9LHOlofEXc2u6Z6PoZeTfWjUwsKrSR/KWcD56u0iJiZfX63cUtaFxgREXMLKyzjscVqKvXoVA+lnA2cLwmS7pA0SNIQ4AHgIklnFV6XD7lUj6RbqL272gb4U/v1RR/H64mUs4HzVT1fG0mzI2JbSUdQ2zs/SdLciNiqyLp8yKWaSj061UMpZwPnS0U/SesDnwG+X3QxbbyHXmFlHZ3KQ8rZwPmqTtKngROBuyPiaEkbA6dHxCcLrcsNvXrKPjrVEylnA+erer6y8yGXaro0+3xGoVX0jpSzgfMlQdJPqN1s7A1qV8RuDRwXEb8ptC7voaehTKNTeUs5GzhfFUmaExHbSDoQOAA4Hrg9IrYusi6PLVZYWUen8pByNnC+BPTPPu9N7VmipXi0nht6ta0TEa8CnwAuiojtgF0LrikvKWcD56u66yU9CowFbpM0HHiz4Jrc0CuufnSq0k+C6UDK2cD5Ki0iTgA+DIyNiLeoPQh7/2Kr8knRqjsFmEZtdGp6Njr1RME15SXlbOB8KdgA2E3SgLpllxRVDPikqJnZCpN0EjAB2AKYCuxF7R+vTxVZlw+5VJikn2QnnvpLuk3Si5I+X3RdeUg5GzhfAj4FfBz4a0QcTm1scfViS3JDr7rdsxNP+1J7CO+mwLeLLSk3KWcD56u6NyLiHWCppEHAC8DGBdfkY+gVt9zolJTCc3iBtLOB81XdDEmDgV8CM4HXgPsLrQg39KprG516Azi6LKNTOUk5GzhfpUXE0dmXkyTdBAwqw4VTPilacdlVeK9GxNuS1qD2F+uvRdeVh5SzgfNVUWeP1mtT9CP23NArTtKHqJ1pf3d0KiIKHZ3KS8rZwPmqqJNH67Up/BF7bugVVtbRqTyknA2cz3qHp1yqrZSjUzlJORs4XyVJ+rykQztY/hVJhxRRUz039Gor5ehUTlLOBs5XVd8Eft/B8iuzdYXylEu1lXJ0KicpZwPnq6q+EfH39gsj4lVJ/Tv6hmbyMfRESBpJSUan8pZyNnC+KpH0CLUbcr3ebvnawPSI2LyYyrI63NCrp+yjUz2RcjZwvgTyfYvauYGvRcRT2bKRwLnAHRFxenHVuaFXUtlHp3oi5WzgfFXPByDpKOC7wFrZoteA0yLiF8VVVeOGbma2EiStRa2HLndMvSiecqmgso9O9UTK2cD5iqgpT5IGSPqipP2oPdTia5KmSPqZpGGF1+c99OqRNBvYqf2eQTYednv2uK9KSjkbOF8C+a4C3gLWBNYFHgSuB3YEtomIfQssz2OLFVXq0akeSjkbOF/VbRERH5LUD2iNiI9ly2+S9ECRhYEPuVRVf0lrtl+YjU6tVkA9eUo5Gzhf1S0BiIilwHPt1r3d/HKW5YZeTb8Crs7GpYB3R6euyNZVWcrZwPmqrkXSzyWdXfd12+sNii7Oh1wqKCLOkPQacGd2ph1KNDrVEylnA+crsLS81D91aUa7de1fN51PilZcGUen8pJyNnA+y58PuVRQ2UeneiLlbOB8RdfXU5J2lPSFutdXS/pj9lH4RVPeQ6+gso9O9UTK2cD5Esh3GzAxIh7OXs8DDqOW93sRsWeB5bmhV5GkB9uNTr23bt0DEbF1geX1SMrZwPkSyDc9IsbVvb42Ij6Rff3niPhocdX5kEtVlXp0qodSzgbOV3WD61+0NfPMes0tZXmecqmmFkk/B1T3NdnrwkeneijlbOB8VfeopH0i4ob6hZL2BR4rqKZ/1uFDLtUj6YtdrY+IXzerlrylnA2cL4F8o4EpwD1A262AtwM+AuwbEY8XVRu4oZuZNUzSCGqP0/sc8MFs8UPA5cC4iPhTUbWBG3olSdoR2DgiLsleXw0MyVafGhF/LKy4Hko5GzhfAvkWAJOAs7LzBEhaDzgT2Kz+hGkRfFK0mn7IslelbUbtCraTgX8roqAcpZwNnK/qtgM2AWZL2kXSsdSelXovsEOhleGGXlWD2uZgM09ExMyIuAtYu6iicpJyNnC+SouIlyPiq8AFwK3U/rH6aEScGxHvFFudG3pVDa5/UbbRqR4aXP8isWzgfJUmabCk84HDgT2Bq4Eby3CVKLihV9WjkvZpv7Aso1M9lHI2cL6qmwU8AYyNiJsj4jjgUOBUSb8ttDJ8UrSSyj461RMpZwPnSyBfS0S0drLuKxHxy2bXVM976NX0JrAV8CdgZPZxV7as6m9rU84GzldpnTXzbF2hzRy8h15JZR+d6omUs4HzVT1f2XkPvZpKPTrVQylnA+ezXuQ99ArL/mf5L2o3QRrf1dvBqkk5Gzif9Q7voVdQ2UeneiLlbOB81ru8h15B2XHK84Cf1h2n3CZb9peIOLjA8nok5WzgfFXPV3Zu6BVU9tGpnkg5Gzhf1fOVnRu6mVkifAzdzCwRbuhmZolwQzczS4QbuplZIv4/tFZT2FDghLQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_plot_bar(df_score.loc['Recall',:].values, df_score_prob.loc['Recall',:].values, df_score, 'Recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использование predict_proba дает лучшие результаты.\n",
    "На исследуемых данных четкой зависимости от доли выборки для положительного класса не наблюдается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>F-Score</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.905315</td>\n",
       "      <td>0.887332</td>\n",
       "      <td>0.848817</td>\n",
       "      <td>0.966759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.025492</td>\n",
       "      <td>0.060267</td>\n",
       "      <td>0.051728</td>\n",
       "      <td>0.032150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.858065</td>\n",
       "      <td>0.787531</td>\n",
       "      <td>0.755682</td>\n",
       "      <td>0.917508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.901660</td>\n",
       "      <td>0.858946</td>\n",
       "      <td>0.839844</td>\n",
       "      <td>0.947527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.911166</td>\n",
       "      <td>0.908111</td>\n",
       "      <td>0.862614</td>\n",
       "      <td>0.973825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.919869</td>\n",
       "      <td>0.921002</td>\n",
       "      <td>0.868637</td>\n",
       "      <td>0.990931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Threshold   F-Score   ROC_AUC  Precision    Recall\n",
       "count        0.0  6.000000  6.000000   6.000000  6.000000\n",
       "mean         NaN  0.905315  0.887332   0.848817  0.966759\n",
       "std          NaN  0.025492  0.060267   0.051728  0.032150\n",
       "min          NaN  0.858065  0.787531   0.755682  0.917508\n",
       "25%          NaN  0.901660  0.858946   0.839844  0.947527\n",
       "50%          NaN  0.911166  0.908111   0.862614  0.973825\n",
       "75%          NaN  0.919869  0.921002   0.868637  0.990931\n",
       "max          NaN  0.930233  0.952381   0.909091  1.000000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score.T.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>F-Score</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.745762</td>\n",
       "      <td>0.958954</td>\n",
       "      <td>0.943833</td>\n",
       "      <td>0.934342</td>\n",
       "      <td>0.940746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.302761</td>\n",
       "      <td>0.020410</td>\n",
       "      <td>0.024297</td>\n",
       "      <td>0.025485</td>\n",
       "      <td>0.025646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.148428</td>\n",
       "      <td>0.939524</td>\n",
       "      <td>0.919540</td>\n",
       "      <td>0.889655</td>\n",
       "      <td>0.913462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.757586</td>\n",
       "      <td>0.944135</td>\n",
       "      <td>0.926392</td>\n",
       "      <td>0.926975</td>\n",
       "      <td>0.917532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.856011</td>\n",
       "      <td>0.951311</td>\n",
       "      <td>0.937908</td>\n",
       "      <td>0.939640</td>\n",
       "      <td>0.940909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.921477</td>\n",
       "      <td>0.973969</td>\n",
       "      <td>0.955289</td>\n",
       "      <td>0.948986</td>\n",
       "      <td>0.960651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.946048</td>\n",
       "      <td>0.988312</td>\n",
       "      <td>0.984007</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Threshold   F-Score   ROC_AUC  Precision    Recall\n",
       "count   6.000000  6.000000  6.000000   6.000000  6.000000\n",
       "mean    0.745762  0.958954  0.943833   0.934342  0.940746\n",
       "std     0.302761  0.020410  0.024297   0.025485  0.025646\n",
       "min     0.148428  0.939524  0.919540   0.889655  0.913462\n",
       "25%     0.757586  0.944135  0.926392   0.926975  0.917532\n",
       "50%     0.856011  0.951311  0.937908   0.939640  0.940909\n",
       "75%     0.921477  0.973969  0.955289   0.948986  0.960651\n",
       "max     0.946048  0.988312  0.984007   0.962264  0.972222"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score_prob.T.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Бонусный вопрос:</b>\n",
    "\n",
    "Как вы думаете, какой из методов на практике является более предпочтительным: random negative sampling или 2-step approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваш ответ здесь:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random negative sampling  - для быстрого расчета\n",
    "### 2-step approach - для более точного"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
