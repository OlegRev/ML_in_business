{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача uplift-моделирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем нужные библиотеки и предобработаем данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd; pd.set_option('display.max_columns', None)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]\n",
    "    \n",
    "class OHEEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.columns = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = [col for col in pd.get_dummies(X, prefix=self.key).columns]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.get_dummies(X, prefix=self.key)\n",
    "        test_columns = [col for col in X.columns]\n",
    "        for col_ in test_columns:\n",
    "            if col_ not in self.columns:\n",
    "                X[col_] = 0\n",
    "        return X[self.columns]\n",
    "\n",
    "\n",
    "class RenameKey(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, new_old_keys_dict):\n",
    "        self.new_old_keys_dict = new_old_keys_dict\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.rename(self.new_old_keys_dict, axis='columns')\n",
    "        return X\n",
    "    \n",
    "    \n",
    "class BinEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key, neg_class='No Offer'):\n",
    "        self.key = key\n",
    "        self.neg_class = neg_class\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X.loc[(X[self.key] != self.neg_class), self.key ] = 1\n",
    "        X.loc[(X[self.key] == self.neg_class), self.key ] = 0\n",
    "        X[self.key] = pd.to_numeric(X[self.key])\n",
    "        return X[[self.key]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. скачать набор данных маркетинговых кампаний отсюда https://www.kaggle.com/davinwijaya/customer-retention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['recency', 'history', 'used_discount', 'used_bogo', 'zip_code',\n",
       "       'is_referral', 'channel', 'offer', 'conversion'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Чтение данных: датасет 'HW_data.csv' скачан в папку с .ipynb \n",
    "df_base = pd.read_csv('HW_data.csv')\n",
    "df_base.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. там поле conversion - это целевая переменная, а offer - коммуникация. \n",
    "### Переименовать поля (conversion -> target, offer -> treatment) и привести поле treatment к бинарному виду (1 или 0, т.е было какое-то предложение или нет) - значение No Offer означает отсутствие коммуникации, а все остальные - наличие.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_feture = RenameKey({'conversion': 'target', 'offer': 'treatment'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = rename_feture.fit_transform(df_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recency</th>\n",
       "      <th>history</th>\n",
       "      <th>used_discount</th>\n",
       "      <th>used_bogo</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>is_referral</th>\n",
       "      <th>channel</th>\n",
       "      <th>treatment</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>142.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Surburban</td>\n",
       "      <td>0</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Buy One Get One</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>329.08</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Rural</td>\n",
       "      <td>1</td>\n",
       "      <td>Web</td>\n",
       "      <td>No Offer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>180.65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Surburban</td>\n",
       "      <td>1</td>\n",
       "      <td>Web</td>\n",
       "      <td>Buy One Get One</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recency  history  used_discount  used_bogo   zip_code  is_referral channel  \\\n",
       "0       10   142.44              1          0  Surburban            0   Phone   \n",
       "1        6   329.08              1          1      Rural            1     Web   \n",
       "2        7   180.65              0          1  Surburban            1     Web   \n",
       "\n",
       "         treatment  target  \n",
       "0  Buy One Get One       0  \n",
       "1         No Offer       0  \n",
       "2  Buy One Get One       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   treatment\n",
       "0          1\n",
       "1          0\n",
       "2          1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatment = BinEncoder(key='treatment')\n",
    "treatment.fit_transform(df_base).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recency</th>\n",
       "      <th>history</th>\n",
       "      <th>used_discount</th>\n",
       "      <th>used_bogo</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>is_referral</th>\n",
       "      <th>channel</th>\n",
       "      <th>treatment</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>142.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Surburban</td>\n",
       "      <td>0</td>\n",
       "      <td>Phone</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>329.08</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Rural</td>\n",
       "      <td>1</td>\n",
       "      <td>Web</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>180.65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Surburban</td>\n",
       "      <td>1</td>\n",
       "      <td>Web</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recency  history  used_discount  used_bogo   zip_code  is_referral channel  \\\n",
       "0       10   142.44              1          0  Surburban            0   Phone   \n",
       "1        6   329.08              1          1      Rural            1     Web   \n",
       "2        7   180.65              0          1  Surburban            1     Web   \n",
       "\n",
       "   treatment  target  \n",
       "0          1       0  \n",
       "1          0       0  \n",
       "2          1       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64000 entries, 0 to 63999\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   recency        64000 non-null  int64  \n",
      " 1   history        64000 non-null  float64\n",
      " 2   used_discount  64000 non-null  int64  \n",
      " 3   used_bogo      64000 non-null  int64  \n",
      " 4   zip_code       64000 non-null  object \n",
      " 5   is_referral    64000 non-null  int64  \n",
      " 6   channel        64000 non-null  object \n",
      " 7   treatment      64000 non-null  int64  \n",
      " 8   target         64000 non-null  int64  \n",
      "dtypes: float64(1), int64(6), object(2)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_base.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. сделать разбиение набора данных не тренировочную и тестовую выборки\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df_base[df_base.columns[:-1]]\n",
    "y = df_base[df_base.columns[-1]]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. сделать feature engineering на ваше усмотрение (допускается свобода выбора методов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_code = Pipeline([\n",
    "                ('selector', ColumnSelector(key='zip_code')),\n",
    "                ('ohe', OHEEncoder(key='zip_code'))\n",
    "            ])\n",
    "channel = Pipeline([\n",
    "                ('selector', ColumnSelector(key='channel')),\n",
    "                ('ohe', OHEEncoder(key='channel'))\n",
    "            ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "recency =  Pipeline([\n",
    "                ('selector', NumberSelector(key='recency')),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "history =  Pipeline([\n",
    "                ('selector', NumberSelector(key='history')),\n",
    "                ('standard', StandardScaler())\n",
    "            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. провести uplift-моделирование 3 способами: одна модель с признаком коммуникации (S learner), модель с трансформацией таргета (трансформация классов п. 2. 1) и вариант с двумя независимыми моделями\n",
    "### 6. в конце вывести единую таблицу сравнения метрик uplift@10%, uplift@20% этих 3 моделей\n",
    "### 7. построить модель UpliftTreeClassifier и попытаться описать словами полученное дерево\n",
    "### 8. (опционально) для модели S learner (модель с дополнительным признаком коммуникации) построить зависимость таргета (конверсии - поле conversion) от значения uplift: 1) сделать прогноз и получить uplift для тестовой выборки 2) отсортировать тестовую выборку по uplift по убыванию 3) разбить на децили (pandas qcut вам в помощь) 4) для каждого дециля посчитать среднюю conversion\n",
    "### 9. (опционально) построить модель UpliftRandomForestClassifier и попытаться описать словами полученное дерево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base['treatment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df_base['treatment'].loc[df_base['treatment'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train = pd.read_csv('uplift_data/uplift_train.csv', index_col='client_id')\n",
    "df_test = pd.read_csv('uplift_data/uplift_test.csv', index_col='client_id')\n",
    "\n",
    "# Извлечение признаков\n",
    "df_features = df_clients.copy()\n",
    "df_features['first_issue_time'] = \\\n",
    "    (pd.to_datetime(df_features['first_issue_date'])\n",
    "     - pd.Timestamp('1970-01-01')) // pd.Timedelta('1s')\n",
    "df_features['first_redeem_time'] = \\\n",
    "    (pd.to_datetime(df_features['first_redeem_date'])\n",
    "     - pd.Timestamp('1970-01-01')) // pd.Timedelta('1s')\n",
    "df_features['issue_redeem_delay'] = df_features['first_redeem_time'] \\\n",
    "    - df_features['first_issue_time']\n",
    "df_features = df_features.drop(['first_issue_date', 'first_redeem_date'], axis=1)\n",
    "\n",
    "indices_train = df_train.index\n",
    "indices_test = df_test.index\n",
    "indices_learn, indices_valid = train_test_split(df_train.index, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.groupby(\"treatment_flg\")['target'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заведем переменные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_features.loc[indices_learn, :]\n",
    "y_train = df_train.loc[indices_learn, 'target']\n",
    "treat_train = df_train.loc[indices_learn, 'treatment_flg']\n",
    "\n",
    "X_val = df_features.loc[indices_valid, :]\n",
    "y_val = df_train.loc[indices_valid, 'target']\n",
    "treat_val =  df_train.loc[indices_valid, 'treatment_flg']\n",
    "\n",
    "X_train_full = df_features.loc[indices_train, :]\n",
    "y_train_full = df_train.loc[:, 'target']\n",
    "treat_train_full = df_train.loc[:, 'treatment_flg']\n",
    "\n",
    "X_test = df_features.loc[indices_test, :]\n",
    "\n",
    "cat_features = ['gender']\n",
    "\n",
    "models_results = {\n",
    "    'approach': [],\n",
    "    'uplift@30%': []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Подходы с одной моделью\n",
    "#### 1.1 Одна модель с признаком коммуникации\n",
    "Самое простое и интуитивное решение: модель обучается одновременно на двух группах, при этом бинарный флаг коммуникации выступает в качестве дополнительного признака. Каждый объект из тестовой выборки скорим дважды: с флагом коммуникации равным 1 и равным 0. Вычитая вероятности по каждому наблюдению, получим искомы uplift."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ab_split](uplift4.png \"uplift4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-0.25.1-cp38-none-win_amd64.whl (66.9 MB)\n",
      "Requirement already satisfied: six in d:\\programming\\anaconda3\\lib\\site-packages (from catboost) (1.15.0)\n",
      "Collecting plotly\n",
      "  Using cached plotly-4.14.3-py2.py3-none-any.whl (13.2 MB)\n",
      "Requirement already satisfied: scipy in d:\\programming\\anaconda3\\lib\\site-packages (from catboost) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in d:\\programming\\anaconda3\\lib\\site-packages (from catboost) (1.20.1)\n",
      "Requirement already satisfied: matplotlib in d:\\programming\\anaconda3\\lib\\site-packages (from catboost) (3.3.4)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.16-py2.py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: pandas>=0.24.0 in d:\\programming\\anaconda3\\lib\\site-packages (from catboost) (1.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in d:\\programming\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in d:\\programming\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2021.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in d:\\programming\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\programming\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\programming\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (8.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\programming\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Collecting retrying>=1.3.3\n",
      "  Using cached retrying-1.3.3-py3-none-any.whl\n",
      "Installing collected packages: retrying, plotly, graphviz, catboost\n",
      "Successfully installed catboost-0.25.1 graphviz-0.16 plotly-4.14.3 retrying-1.3.3\n"
     ]
    }
   ],
   "source": [
    "# !pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-uplift==0.2.0\n",
      "  Downloading scikit_uplift-0.2.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: matplotlib in d:\\programming\\anaconda3\\lib\\site-packages (from scikit-uplift==0.2.0) (3.3.4)\n",
      "Requirement already satisfied: pandas in d:\\programming\\anaconda3\\lib\\site-packages (from scikit-uplift==0.2.0) (1.2.4)\n",
      "Requirement already satisfied: numpy>=1.16 in d:\\programming\\anaconda3\\lib\\site-packages (from scikit-uplift==0.2.0) (1.20.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.0 in d:\\programming\\anaconda3\\lib\\site-packages (from scikit-uplift==0.2.0) (0.24.1)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\programming\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.0->scikit-uplift==0.2.0) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in d:\\programming\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.0->scikit-uplift==0.2.0) (1.6.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\programming\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.0->scikit-uplift==0.2.0) (2.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\programming\\anaconda3\\lib\\site-packages (from matplotlib->scikit-uplift==0.2.0) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\programming\\anaconda3\\lib\\site-packages (from matplotlib->scikit-uplift==0.2.0) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in d:\\programming\\anaconda3\\lib\\site-packages (from matplotlib->scikit-uplift==0.2.0) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\programming\\anaconda3\\lib\\site-packages (from matplotlib->scikit-uplift==0.2.0) (8.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in d:\\programming\\anaconda3\\lib\\site-packages (from matplotlib->scikit-uplift==0.2.0) (2.4.7)\n",
      "Requirement already satisfied: six in d:\\programming\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->scikit-uplift==0.2.0) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in d:\\programming\\anaconda3\\lib\\site-packages (from pandas->scikit-uplift==0.2.0) (2021.1)\n",
      "Installing collected packages: scikit-uplift\n",
      "Successfully installed scikit-uplift-0.2.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install scikit-uplift==0.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инструкция по установке пакета: https://github.com/maks-sh/scikit-uplift\n",
    "# Ссылка на документацию: https://scikit-uplift.readthedocs.io/en/latest/\n",
    "from sklift.metrics import uplift_at_k\n",
    "from sklift.viz import plot_uplift_preds\n",
    "from sklift.models import SoloModel\n",
    "\n",
    "# sklift поддерживает любые модели, \n",
    "# которые удовлетворяют соглашениями scikit-learn\n",
    "# Для примера воспользуемся catboost\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "sm = SoloModel(CatBoostClassifier(iterations=20, thread_count=2, random_state=42, silent=True))\n",
    "sm = sm.fit(X_train, y_train, treat_train, estimator_fit_params={'cat_features': cat_features})\n",
    "\n",
    "uplift_sm = sm.predict(X_val)\n",
    "\n",
    "sm_score = uplift_at_k(y_true=y_val, uplift=uplift_sm, treatment=treat_val, strategy='by_group', k=0.3)\n",
    "print(f'uplift@30%: {sm_score:.4f}')\n",
    "\n",
    "models_results['approach'].append('SoloModel')\n",
    "models_results['uplift@30%'].append(sm_score)\n",
    "\n",
    "# Получим условные вероятности выполнения целевого действия при взаимодействии для каждого объекта\n",
    "sm_trmnt_preds = sm.trmnt_preds_\n",
    "# И условные вероятности выполнения целевого действия без взаимодействия для каждого объекта\n",
    "sm_ctrl_preds = sm.ctrl_preds_\n",
    "\n",
    "# Отрисуем распределения вероятностей и их разность (uplift)\n",
    "plot_uplift_preds(trmnt_preds=sm_trmnt_preds, ctrl_preds=sm_ctrl_preds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на топ-признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# С той же легкостью можно обратиться к обученной модели.\n",
    "# Например, чтобы построить важность признаков:\n",
    "sm_fi = pd.DataFrame({\n",
    "    'feature_name': sm.estimator.feature_names_,\n",
    "    'feature_score': sm.estimator.feature_importances_\n",
    "}).sort_values('feature_score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "sm_fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Трансформация классов\n",
    "Достаточно интересный и математически подтвержденный подход к построению модели, представленный еще в 2012 году. Метод заключается в прогнозировании немного измененного таргета:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ab_split](uplift5.png \"uplift5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ab_split](uplift_client_types.png \"uplift_client_types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklift.models import ClassTransformation\n",
    "\n",
    "\n",
    "ct = ClassTransformation(CatBoostClassifier(iterations=20, thread_count=2, random_state=42, silent=True))\n",
    "ct = ct.fit(X_train, y_train, treat_train, estimator_fit_params={'cat_features': cat_features})\n",
    "\n",
    "uplift_ct = ct.predict(X_val)\n",
    "\n",
    "ct_score = uplift_at_k(y_true=y_val, uplift=uplift_ct, treatment=treat_val, strategy='by_group', k=0.3)\n",
    "\n",
    "models_results['approach'].append('ClassTransformation')\n",
    "models_results['uplift@30%'].append(ct_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Две независимые модели\n",
    "Как понятно из названия, подход заключается в моделировании условных вероятностей тестовой и контрольной групп отдельно. В статьях утверждается, что такой подход достаточно слабый, так как обе модели фокусируются на прогнозировании результата отдельно и поэтому могут пропустить \"более слабые\" различия в выборках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ab_split](uplift6.png \"uplift6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklift.models import TwoModels\n",
    "\n",
    "\n",
    "tm = TwoModels(\n",
    "    estimator_trmnt=CatBoostClassifier(iterations=20, thread_count=2, random_state=42, silent=True), \n",
    "    estimator_ctrl=CatBoostClassifier(iterations=20, thread_count=2, random_state=42, silent=True), \n",
    "    method='vanilla'\n",
    ")\n",
    "tm = tm.fit(\n",
    "    X_train, y_train, treat_train,\n",
    "    estimator_trmnt_fit_params={'cat_features': cat_features}, \n",
    "    estimator_ctrl_fit_params={'cat_features': cat_features}\n",
    ")\n",
    "\n",
    "uplift_tm = tm.predict(X_val)\n",
    "\n",
    "tm_score = uplift_at_k(y_true=y_val, uplift=uplift_tm, treatment=treat_val, strategy='by_group', k=0.3)\n",
    "\n",
    "models_results['approach'].append('TwoModels')\n",
    "models_results['uplift@30%'].append(tm_score)\n",
    "\n",
    "plot_uplift_preds(trmnt_preds=tm.trmnt_preds_, ctrl_preds=tm.ctrl_preds_);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=models_results).sort_values('uplift@30%', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вариант с деревом решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tree = pd.concat([X_train.drop('gender', 1), \n",
    "                          pd.get_dummies(X_train['gender'], prefix='gender')], 1)\n",
    "features = [col for col in X_train_tree]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/ub8er/causalml.git\n",
    "# %cd causalml\n",
    "# !pip install -r requirements.txt\n",
    "# !python setup.py build_ext --inplace\n",
    "# !python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from IPython.display import Image\n",
    "from causalml.inference.tree import UpliftTreeClassifier, UpliftRandomForestClassifier\n",
    "from causalml.inference.tree import uplift_tree_string, uplift_tree_plot\n",
    "\n",
    "uplift_model = UpliftTreeClassifier(max_depth=8, min_samples_leaf=200, min_samples_treatment=50,\n",
    "                                    n_reg=100, evaluationFunction='KL', control_name='control')\n",
    "\n",
    "uplift_model.fit(X_train_tree.values,\n",
    "                 treatment=treat_train.map({1: 'treatment1', 0: 'control'}).values,\n",
    "                 y=y_train)\n",
    "\n",
    "graph = uplift_tree_plot(uplift_model.fitted_uplift_tree, features)\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ссылки\n",
    "\n",
    "1. https://towardsdatascience.com/a-quick-uplift-modeling-introduction-6e14de32bfe0\n",
    "2. https://habr.com/ru/company/ru_mts/blog/485980/#reference1\n",
    "3. https://en.wikipedia.org/wiki/Uplift_modelling\n",
    "4. https://www.youtube.com/watch?v=yFQAIJBYXI0\n",
    "5. https://www.youtube.com/watch?v=jCUcYiBK03I\n",
    "6. https://www.uplift-modeling.com/en/latest/\n",
    "7. https://arxiv.org/pdf/1809.04559.pdf\n",
    "8. https://catboost.ai/docs/concepts/about.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Библиотеки и пакеты\n",
    "\n",
    "1. causalml\n",
    "2. sklift\n",
    "3. catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement sklift\n",
      "ERROR: No matching distribution found for sklift\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
